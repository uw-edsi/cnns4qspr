{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains functions for loading a pdb file and calculating\n",
    "the atomic density fields for different atom types. The fields can then be\n",
    "used for plotting, or to send into the convolutional neural network.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from biopandas.pdb import PandasPdb\n",
    "from biopandas.mol2 import PandasMol2\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pybel\n",
    "from math import ceil, sin, cos, sqrt, pi\n",
    "from itertools import combinations\n",
    "from silx.io.dictdump import dicttoh5\n",
    "import h5py\n",
    "import click\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "from   scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "import numpy as np\n",
    "from   numpy.linalg import eig, inv\n",
    "\n",
    "STD = 0.3455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdb(path):\n",
    "\n",
    "    pdb = PandasPdb().read_pdb(path)\n",
    "# This just creates a dataframe from the pdb file using biopandas\n",
    "#print('This is vars',vars(pdb))\n",
    "    pdf = pdb.df['ATOM']\n",
    "    x_coords = pdf['x_coord'].values\n",
    "    y_coords = pdf['y_coord'].values\n",
    "    z_coords = pdf['z_coord'].values\n",
    "    atom_types = pdf['atom_name'].values\n",
    "    residue_names = pdf['residue_name'].values\n",
    "    \n",
    "    pro_dict = generate_dict(x_coords, y_coords, z_coords, atom_types, residue_names)\n",
    "    # add a value to the dictionary, which is all of the atomic coordinates just\n",
    "    # shifted to the origin\n",
    "    #protein_dict = shift_coords(protein_dict)\n",
    "\n",
    "    return pro_dict\n",
    "\n",
    "\n",
    "\n",
    "def load_mol2(path):\n",
    "    \n",
    "    mol = PandasMol2().read_mol2(path)\n",
    "    pdf = mol\n",
    "    x_coords = pdf.df['x'].values\n",
    "    y_coords = pdf.df['y'].values\n",
    "    z_coords = pdf.df['z'].values\n",
    "    atom_types = pdf.df['atom_name'].values\n",
    "    residue_names = pdf.df['subst_name'].values\n",
    "    partial_charge = pdf.df['charge'].values\n",
    "    smarts_notation = next(pybel.readfile('mol2', path))\n",
    "    \n",
    "    pro_dict = generate_dict(x_coords, y_coords, z_coords, atom_types, residue_names)\n",
    "    heavy_pos = heavy_atom_positions(x_coords, y_coords, z_coords, atom_types)\n",
    "\n",
    "    pro_dict['charge'] = partial_charge\n",
    "    pro_dict['smarts'] = smarts_notation\n",
    "    pro_dict['heavy_atom_positions'] = heavy_pos\n",
    "\n",
    "    # add a value to the dictionary, which is all of the atomic coordinates just\n",
    "    # shifted to the origin\n",
    "    #protein_dict = shift_coords(protein_dict)\n",
    "\n",
    "    return pro_dict\n",
    "    \n",
    "def generate_dict(x, y, z, a_types, res_names):\n",
    "    \n",
    "    positions = []\n",
    "    for i, xi in enumerate(x):\n",
    "        position_tuple = (x[i], y[i], z[i])\n",
    "        positions.append(position_tuple)\n",
    "    positions = np.array(positions)\n",
    "\n",
    "    # names of all the atoms contained in the protein\n",
    "    \n",
    "    num_atoms = len(a_types)\n",
    "    atom_type_set = np.unique(a_types)\n",
    "    num_atom_types = len(atom_type_set)\n",
    "\n",
    "    # residue names\n",
    "    \n",
    "    residue_set = np.unique(res_names)\n",
    "\n",
    "    pro_dict = {'x_coords':x, 'y_coords':y, 'z_coords':z,\n",
    "                    'positions':positions, 'atom_types':a_types,\n",
    "                    'num_atoms':num_atoms, 'atom_type_set':atom_type_set,\n",
    "                    'num_atom_types':num_atom_types, 'residues':res_names,\n",
    "                    'residue_set':residue_set}\n",
    "    \n",
    "    return pro_dict\n",
    "\n",
    "def heavy_atom_positions(x, y, z, a_types):\n",
    "    \n",
    "    positions = []\n",
    "    for i, xi in enumerate(x):\n",
    "        if a_types[i].startswith('H'):\n",
    "            pass\n",
    "        else:\n",
    "            position_tuple = (x[i], y[i], z[i])\n",
    "            positions.append(position_tuple)\n",
    "    positions = np.array(positions)\n",
    "    \n",
    "    return positions\n",
    "\n",
    "\n",
    "def load_input(path, ligand=False):\n",
    "    \"\"\"\n",
    "    Loads all of the atomic positioning/type arrays from a pdb/mol2 file.\n",
    "    The arrays can then be transformed into density (or \"field\") tensors before\n",
    "        being sent through the neural network.\n",
    "    Parameters:\n",
    "        path (str, required): The full path to the pdb file being voxelized.\n",
    "    Returns:\n",
    "        dictionary: A dictionary containing the following arrays from\n",
    "            the pdb file: num_atoms, atom_types, positions, atom_type_set,\n",
    "            xcoords, ycoords, zcoords, residues, residue_set\n",
    "    \"\"\"\n",
    "    \n",
    "    file_type = path.split('.')[-1]\n",
    "    \n",
    "    if file_type == 'pdb':\n",
    "        protein_dict = load_pdb(path)\n",
    "    \n",
    "    elif file_type == 'mol2':\n",
    "        protein_dict = load_mol2(path)\n",
    "    else:\n",
    "        raise ValueError('Need a pdb or mol2 file')\n",
    "    # atomic coordinates\n",
    "    if ligand == True:\n",
    "        ligand_file = path.split('_')[:-1][0] + '_ligand.mol2'\n",
    "        ligand_dict = load_mol2(ligand_file)\n",
    "        mid_points = shift_coords(protein_dict, lig_dict=ligand_dict)\n",
    "        #mid_points = shift_coords(ligand_dict, lig_dict=None)\n",
    "        protein_dict['shifted_positions'] = protein_dict['positions'] - mid_points\n",
    "        ligand_dict['shifted_positions'] = ligand_dict['positions'] - mid_points\n",
    "        \n",
    "        return protein_dict, ligand_dict\n",
    "    else:\n",
    "        mid_points = shift_coords(protein_dict)\n",
    "        protein_dict['shifted_positions'] = protein_dict['positions'] - mid_points\n",
    "        \n",
    "        return protein_dict\n",
    "        \n",
    "\n",
    "    # create an array containing tuples of x,y,z for every atom\n",
    "    \n",
    "def get_extreme_values(name_dict):\n",
    "    \n",
    "    x_ext = np.array([name_dict['x_coords'].min(), name_dict['x_coords'].max()])\n",
    "    y_ext = np.array([name_dict['y_coords'].min(), name_dict['y_coords'].max()])\n",
    "    z_ext = np.array([name_dict['z_coords'].min(), name_dict['z_coords'].max()])\n",
    "    \n",
    "    return x_ext, y_ext, z_ext\n",
    "\n",
    "def shift_coords(pro_dict, lig_dict=None):\n",
    "    \"\"\"\n",
    "    This function shifts the coordinates of a protein so that it's coordinates are in the center\n",
    "    of the field tensor.\n",
    "    Parameters:\n",
    "        protein_dict (dict): A dictionary of information from the first part of the load_input function.\n",
    "    Returns:\n",
    "        dictionary: The original protein dict but with an added value containing\n",
    "            the coordinates of the protein shifted to the origin.\n",
    "    \"\"\"\n",
    "    # find the extreme x, y, and z values that exist in the protein atomic coordinates\n",
    " \n",
    "    x_extremes, y_extremes, z_extremes = get_extreme_values(pro_dict)\n",
    "        \n",
    "\n",
    "    if lig_dict:\n",
    "        x_pro, y_pro, z_pro = get_extreme_values(pro_dict)\n",
    "        x_lig, y_lig, z_lig = get_extreme_values(lig_dict)\n",
    "        x_extremes, y_extremes, z_extremes = get_extreme_values(lig_dict)\n",
    "        \n",
    "#         x_extremes = np.array([np.min(np.concatenate([x_pro, x_lig])), np.max(np.concatenate([x_pro, x_lig]))])\n",
    "#         y_extremes = np.array([np.min(np.concatenate([y_pro, y_lig])), np.max(np.concatenate([y_pro, y_lig]))])\n",
    "#         z_extremes = np.array([np.min(np.concatenate([z_pro, z_lig])), np.max(np.concatenate([z_pro, z_lig]))])\n",
    "        \n",
    "        #x_val = np.concatenate(x_pro, x_lig)\n",
    "        #print(x_extremes)\n",
    "    # calculate the midpoints of the extremes\n",
    "    midpoints = [np.sum(x_extremes)/2, np.sum(y_extremes)/2, np.sum(z_extremes)/2]\n",
    "#     print(x_extremes, y_extremes, z_extremes)\n",
    "\n",
    "    # shift the coordinates by the midpoints of those extremes (center the protein on the origin)\n",
    "#     protein_dict['shifted_positions'] = protein_dict['positions'] - midpoints\n",
    "\n",
    "    return midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "from random import random\n",
    "\n",
    "class EllipsoidTool:\n",
    "    \"\"\"Some stuff for playing with ellipsoids\"\"\"\n",
    "    def __init__(self): pass\n",
    "    \n",
    "    def getMinVolEllipse(self, P=None, tolerance=0.01):\n",
    "        \"\"\" Find the minimum volume ellipsoid which holds all the points\n",
    "        \n",
    "        Based on work by Nima Moshtagh\n",
    "        http://www.mathworks.com/matlabcentral/fileexchange/9542\n",
    "        and also by looking at:\n",
    "        http://cctbx.sourceforge.net/current/python/scitbx.math.minimum_covering_ellipsoid.html\n",
    "        Which is based on the first reference anyway!\n",
    "        \n",
    "        Here, P is a numpy array of N dimensional points like this:\n",
    "        P = [[x,y,z,...], <-- one point per line\n",
    "             [x,y,z,...],\n",
    "             [x,y,z,...]]\n",
    "        \n",
    "        Returns:\n",
    "        (center, radii, rotation)\n",
    "        \n",
    "        \"\"\"\n",
    "        (N, d) = np.shape(P)\n",
    "        d = float(d)\n",
    "    \n",
    "        # Q will be our working array\n",
    "        Q = np.vstack([np.copy(P.T), np.ones(N)]) \n",
    "        QT = Q.T\n",
    "        \n",
    "        # initializations\n",
    "        err = 1.0 + tolerance\n",
    "        u = (1.0 / N) * np.ones(N)\n",
    "\n",
    "        # Khachiyan Algorithm\n",
    "        while err > tolerance:\n",
    "            V = np.dot(Q, np.dot(np.diag(u), QT))\n",
    "            M = np.diag(np.dot(QT , np.dot(linalg.inv(V), Q)))    # M the diagonal vector of an NxN matrix\n",
    "            j = np.argmax(M)\n",
    "            maximum = M[j]\n",
    "            step_size = (maximum - d - 1.0) / ((d + 1.0) * (maximum - 1.0))\n",
    "            new_u = (1.0 - step_size) * u\n",
    "            new_u[j] += step_size\n",
    "            err = np.linalg.norm(new_u - u)\n",
    "            u = new_u\n",
    "\n",
    "        # center of the ellipse \n",
    "        center = np.dot(P.T, u)\n",
    "    \n",
    "        # the A matrix for the ellipse\n",
    "        A = linalg.inv(\n",
    "                       np.dot(P.T, np.dot(np.diag(u), P)) - \n",
    "                       np.array([[a * b for b in center] for a in center])\n",
    "                       ) / d\n",
    "                       \n",
    "        # Get the values we'd like to return\n",
    "        U, s, rotation = linalg.svd(A)\n",
    "        radii = 1.0/np.sqrt(s)\n",
    "        \n",
    "        return (center, radii, rotation)\n",
    "\n",
    "    def getEllipsoidVolume(self, radii):\n",
    "        \"\"\"Calculate the volume of the blob\"\"\"\n",
    "        return 4./3.*np.pi*radii[0]*radii[1]*radii[2]\n",
    "\n",
    "    def plotEllipsoid(self, center, radii, rotation, ax=None, plotAxes=False, cageColor='b', cageAlpha=0.2):\n",
    "        \"\"\"Plot an ellipsoid\"\"\"\n",
    "        make_ax = ax == None\n",
    "        if make_ax:\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "        u = np.linspace(0.0, 2.0 * np.pi, 100)\n",
    "        v = np.linspace(0.0, np.pi, 100)\n",
    "        \n",
    "        # cartesian coordinates that correspond to the spherical angles:\n",
    "        x = radii[0] * np.outer(np.cos(u), np.sin(v))\n",
    "        y = radii[1] * np.outer(np.sin(u), np.sin(v))\n",
    "        z = radii[2] * np.outer(np.ones_like(u), np.cos(v))\n",
    "        # rotate accordingly\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x)):\n",
    "                [x[i,j],y[i,j],z[i,j]] = np.dot([x[i,j],y[i,j],z[i,j]], rotation) + center\n",
    "    \n",
    "        if plotAxes:\n",
    "            # make some purdy axes\n",
    "            axes = np.array([[radii[0],0.0,0.0],\n",
    "                             [0.0,radii[1],0.0],\n",
    "                             [0.0,0.0,radii[2]]])\n",
    "            # rotate accordingly\n",
    "            for i in range(len(axes)):\n",
    "                axes[i] = np.dot(axes[i], rotation)\n",
    "    \n",
    "    \n",
    "            # plot axes\n",
    "            for p in axes:\n",
    "                X3 = np.linspace(-p[0], p[0], 100) + center[0]\n",
    "                Y3 = np.linspace(-p[1], p[1], 100) + center[1]\n",
    "                Z3 = np.linspace(-p[2], p[2], 100) + center[2]\n",
    "                ax.plot(X3, Y3, Z3, color=cageColor)\n",
    "    \n",
    "        # plot ellipsoid\n",
    "        ax.plot_wireframe(x, y, z,  rstride=4, cstride=4, color=cageColor, alpha=cageAlpha)\n",
    "        \n",
    "        if make_ax:\n",
    "            plt.show()\n",
    "            plt.close(fig)\n",
    "            del fig\n",
    "            \n",
    "    def rotate_position(self, ligand_heavy, protein_heavy, ligand_all, protein_all, center, rotation_mat):\n",
    "\n",
    "\n",
    "        ligand_heavy = ligand_heavy - center\n",
    "        ligand_heavy_rotated = np.dot(ligand_heavy, rotation_mat)\n",
    "        \n",
    "        protein_heavy = protein_heavy - center\n",
    "        protein_heavy_rotated = np.dot(protein_heavy, rotation_mat)\n",
    "\n",
    "        ligand_all = ligand_all - center \n",
    "        ligand_rotated = np.dot(ligand_all, rotation_mat)\n",
    "\n",
    "        protein_all = protein_all - center \n",
    "        protein_rotated = np.dot(protein_all, rotation_mat)\n",
    "\n",
    "        return protein_rotated, ligand_rotated, ligand_heavy_rotated, protein_heavy_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1a1e'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '1a1e_ligand.mol2'\n",
    "path.split('_')[:-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_positions(grid_array):\n",
    "    \"\"\"\n",
    "    This function returns the 3D meshgrids of x, y and z positions.\n",
    "    These cubes will be flattened, then used as a reference coordinate system\n",
    "    to place the actual channel densities into.\n",
    "    Parameters:\n",
    "        grid_positions (pytorch tensor): lineraly spaced grid\n",
    "    Returns:\n",
    "        array: meshgrid array of the x, y and z positions.\n",
    "    \"\"\"\n",
    "    xgrid = grid_array.view(-1, 1, 1).repeat(1, len(grid_array), len(grid_array))\n",
    "    ygrid = grid_array.view(1, -1, 1).repeat(len(grid_array), 1, len(grid_array))\n",
    "    zgrid = grid_array.view(1, 1, -1).repeat(len(grid_array), len(grid_array), 1)\n",
    "    return (xgrid, ygrid, zgrid)\n",
    "\n",
    "# def norm_properties(prop, channel):\n",
    "    \n",
    "#     if channel == 'hyb':\n",
    "#         max_prop = 3\n",
    "#         min_prop = 0\n",
    "#     elif channel == 'heterovalence':\n",
    "#         max_prop = 4\n",
    "#         min_prop = 0\n",
    "#     elif channel == 'heavyvalence':\n",
    "#         max_prop = 4\n",
    "#         min_prop = 0\n",
    "#     else:\n",
    "#         max_prop = 2.276\n",
    "#         min_prop = -1.167\n",
    "#         # clamping the charge value within a range\n",
    "#         # the range is chosen from ligand data\n",
    "#         prop[prop > 2.276] = 2.276\n",
    "#         prop[prop < -1.166] = -1.167\n",
    "    \n",
    "#     norm_prop = (prop-min_prop)/(max_prop-min_prop)\n",
    "    \n",
    "#     return norm_prop\n",
    "\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "        # Extract positions of atoms that are part of the current channel\n",
    "\n",
    "        \n",
    "#         if feature_type == 'nearest':\n",
    "            \n",
    "#             atom_positions = np.array(atom_positions).reshape(len(atom_positions), 3)\n",
    "#             prop = np.array(prop).reshape(len(atom_positions))\n",
    "#             voxel = make_voxel_grids(atom_positions, prop, bin_size, num_bins)\n",
    "            \n",
    "                           \n",
    "\n",
    "\n",
    "\n",
    "                           \n",
    "def make_voxel_grids(coords, feature=None, bin_size=1.0, num_bins=30):\n",
    "    \"\"\"Convert atom coordinates and features represented as 2D arrays into a\n",
    "    fixed-sized 3D box.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coords, features: array-likes, shape (N, 3) and (N, )\n",
    "        Arrays with coordinates and features for each atoms.\n",
    "    grid_resolution: float, optional\n",
    "        Resolution of a grid (in Angstroms).\n",
    "    max_dist: float, optional\n",
    "        Maximum distance between atom and box center. Resulting box has size of\n",
    "        bin_size * num_bins +1 Angstroms and atoms that are too far away are not\n",
    "        included.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coords: np.ndarray, shape = (M, M, M, F)\n",
    "        4D array with atom properties distributed in 3D space. M is equal to\n",
    "        2 * `max_dist` / `grid_resolution` + 1\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        coords = np.asarray(coords, dtype=np.float)\n",
    "    except ValueError:\n",
    "        raise ValueError('coords must be an array of floats of shape (N, 3)')\n",
    "    c_shape = coords.shape\n",
    "    if len(c_shape) != 2 or c_shape[1] != 3:\n",
    "        raise ValueError('coords must be an array of floats of shape (N, 3)')\n",
    "\n",
    "    N = len(coords)\n",
    "#     try:\n",
    "#         features = np.asarray(features, dtype=np.float)\n",
    "#     except ValueError:\n",
    "#         raise ValueError('features must be an array of floats of shape (N, F)')\n",
    "#     f_shape = features.shape\n",
    "#     if len(f_shape) != 2 or f_shape[0] != N:\n",
    "#         raise ValueError('features must be an array of floats of shape (N, F)')\n",
    "\n",
    "    if not isinstance(bin_size, (float, int)):\n",
    "        raise TypeError('bin_size must be float')\n",
    "    if bin_size <= 0:\n",
    "        raise ValueError('bin_size must be positive')\n",
    "\n",
    "    if not isinstance(num_bins, int):\n",
    "        raise TypeError('num_bins must be integer')\n",
    "    if num_bins <= 0:\n",
    "        raise ValueError('num_bins must be positive')\n",
    "\n",
    "    # num_features = f_shape[1]\n",
    "    num_bins = float(num_bins)\n",
    "    bin_size = float(bin_size)\n",
    "\n",
    "    box_size = ceil(num_bins * bin_size)\n",
    "#     print(box_size)\n",
    "\n",
    "    # move all atoms to the neares grid point\n",
    "    grid_coords_original = coords + bin_size * num_bins / 2.0\n",
    "    grid_coords = grid_coords_original.round().astype(int)\n",
    "    #print(grid_coords)\n",
    "    # remove atoms outside the box\n",
    "    in_box = ((grid_coords > 0) & (grid_coords < box_size)).all(axis=1)\n",
    "    #print(in_box)\n",
    "#     voxel_grid = np.zeros((1, box_size, box_size, box_size),\n",
    "#                     dtype=np.float32)\n",
    "    return grid_coords_original[in_box], grid_coords[in_box]\n",
    "#     for (x, y, z), f in zip(grid_coords[in_box], feature[in_box]):\n",
    "#         voxel_grid[0, x, y, z] += f\n",
    "#     #print(np.count_nonzero(voxel_grid))\n",
    "\n",
    "#     return voxel_grid\n",
    "\n",
    "\n",
    "def voxelize(path, channels=['CA'], path_type='file', ligand=False, bin_size=2.0, num_bins=50, save=False, save_fn='voxels.npy', save_path='./'):\n",
    "    \"\"\"\n",
    "    This function creates a dictionary of tensor fields directly from a pdb file.\n",
    "    These tensor fields can be plotted, or sent directly into the cnn for\n",
    "        plotting internals, or sent all the way through a cnn/vae to be used for\n",
    "        training.\n",
    "    Parameters:\n",
    "        path (str, required): path to a .pdb file\n",
    "        channels (list of strings, optional): The list of atomic channels to be included in\n",
    "            the output dictionary, one field for every channel.\n",
    "            Any channels from points 1-4 below may be combined in any order.\n",
    "            i.e., one could call voxelize with the channels parameter as\n",
    "            channels=['charged', 'CB', 'GLY', 'polar', ...etc]. Note that voxelization\n",
    "            for channels containing more atoms will take longer.\n",
    "            1. any of the following atom types\n",
    "                ['C' 'CA' 'CB' 'CD' 'CD1' 'CD2' 'CE' 'CE1' 'CE2' 'CE3' 'CG' 'CG1' 'CG2'\n",
    "                'CH2' 'CZ' 'CZ2' 'CZ3' 'N' 'ND1' 'ND2' 'NE' 'NE1' 'NE2' 'NH1' 'NH2' 'NZ'\n",
    "                'O' 'OD1' 'OD2' 'OE1' 'OE2' 'OG' 'OG1' 'OH' 'OXT' 'SD' 'SG']\n",
    "            2. Any canonical residue in the protein, using the three letter residue code, all caps\n",
    "               (NOTE: the residue must actually exist in the protein)\n",
    "                e.g., ['LYS', 'LEU', 'ALA']\n",
    "            3. The 'other' channel options: 'backbone', 'sidechains'\n",
    "            4. There are 6 channels corresponding to specific types of residues:\n",
    "                'charged', 'polar', 'nonpolar', 'amphipathic', 'acidic', 'basic'\n",
    "    Returns:\n",
    "        dictionary: a dictionary containing a voxelized atomic fields, one for each\n",
    "        channel requested. Each field has shape = ([1, 1, 50, 50, 50])\n",
    "    \"\"\"\n",
    "    if path_type == 'file':\n",
    "        pro_dict = load_input(path, ligand=ligand)\n",
    "        if ligand == True:\n",
    "            protein_dict = pro_dict[0]\n",
    "            ligand_dict = pro_dict[1]\n",
    "            ligand_heavy = ligand_dict['heavy_atom_positions']\n",
    "            protein_heavy = protein_dict['heavy_atom_positions']\n",
    "            \n",
    "            ligand = ligand_dict['positions']\n",
    "            protein = protein_dict['positions']\n",
    "\n",
    "            \n",
    "            x_ext = np.array([ligand[:,0].min(), ligand[:,0].max()])\n",
    "            y_ext = np.array([ligand[:,1].min(), ligand[:,1].max()])\n",
    "            z_ext = np.array([ligand[:,2].min(), ligand[:,2].max()])\n",
    "            \n",
    "            midpoints = [np.sum(x_ext)/2, np.sum(y_ext)/2, np.sum(z_ext)/2]\n",
    "            ligand = ligand - midpoints\n",
    "            protein = protein - midpoints\n",
    "            ligand_heavy = ligand_heavy - midpoints\n",
    "            protein_heavy = protein_heavy - midpoints\n",
    "            \n",
    "            ET = EllipsoidTool()\n",
    "            (center, radii, rotation) = ET.getMinVolEllipse(ligand_heavy, .01)\n",
    "            \n",
    "            ligand_heavy  = np.dot(ligand_heavy, np.transpose(rotation))\n",
    "            protein, ligand, ligand_heavy, protein_heavy = ET.rotate_position(ligand_heavy,\n",
    "                                                                              protein_heavy, \n",
    "                                                                              ligand, protein, \n",
    "                                                                              center, np.transpose(rotation))\n",
    "            \n",
    "            (center, radii, rotation) = ET.getMinVolEllipse(ligand_heavy, .01)\n",
    "            \n",
    "            rotation = np.array([[0.707, 0, 0.707], \n",
    "                                    [0.5, 0.707, -0.5], \n",
    "                                    [-0.5, 0.707, 0.5]])\n",
    "            protein, ligand, ligand_heavy, protein_heavy = ET.rotate_position(ligand_heavy, \n",
    "                                                                              protein_heavy, ligand, protein, \n",
    "                                                                              center, np.transpose(rotation))\n",
    "\n",
    "            (center, radii, rotation) = ET.getMinVolEllipse(ligand_heavy, .01)\n",
    "            \n",
    "            ligand_dict['positions'] = ligand\n",
    "            protein_dict['positions'] = protein\n",
    "            ligand_dict['heavy_atom_positions'] = ligand_heavy\n",
    "            protein_dict['heavy_atom_positions'] = protein_heavy\n",
    "            actual, grid = make_voxel_grids(protein_heavy)\n",
    "\n",
    "            dist = []\n",
    "            for i in range(len(actual)):\n",
    "#                print(ligand_heavy[i])\n",
    "                dist.append(np.around(np.linalg.norm(actual[i] - grid[i]), 4))\n",
    "            print(dist)\n",
    "            \n",
    "            with open('protein_atoms.txt', 'w') as file_handler:\n",
    "                for item in dist:\n",
    "                    file_handler.write(\"{}\\n\".format(item))\n",
    "            \n",
    "            \n",
    "            \n",
    "#             return make_fields(protein_dict, channels=channels, bin_size=bin_size, num_bins=num_bins, ligand=True, ligand_dict=ligand_dict)\n",
    "#         else:\n",
    "#             protein_dict = pro_dict\n",
    "#             sys.stdout.write('done')\n",
    "#             return make_fields(protein_dict, channels=channels, bin_size=bin_size, num_bins=num_bins)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = '1a1b_pocket.mol2'\n",
    "myprotein_dict = load_input(file_name, ligand=True)\n",
    "len(myprotein_dict[1]['positions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6185, 0.7471, 0.5537, 0.5779, 0.5163, 0.5607, 0.3892, 0.3415, 0.4239, 0.5411, 0.5206, 0.3932, 0.4309, 0.4669, 0.715, 0.4989, 0.436, 0.358, 0.6041, 0.7832, 0.4909, 0.4945, 0.4847, 0.3405, 0.428, 0.4051, 0.3845, 0.5377, 0.4743, 0.6932, 0.6568, 0.7234, 0.574, 0.294, 0.3722, 0.442, 0.5601, 0.4354, 0.564, 0.6137, 0.528, 0.5862, 0.5898, 0.4976, 0.6588, 0.603, 0.5399, 0.7765, 0.421, 0.493, 0.2265, 0.4949, 0.189, 0.5933, 0.37, 0.4617, 0.6576, 0.2964, 0.4651, 0.5324, 0.6309, 0.4155, 0.3508, 0.5438, 0.5471, 0.4028, 0.5608, 0.6328, 0.2854, 0.6003, 0.3107, 0.5106, 0.6839, 0.5637, 0.3565, 0.2519, 0.6254, 0.2837, 0.5405, 0.3672, 0.6472, 0.4916, 0.52, 0.7308, 0.3634, 0.521, 0.3324, 0.3957, 0.3102, 0.3797, 0.448, 0.4127, 0.3959, 0.5362, 0.5135, 0.4644, 0.7695, 0.4709, 0.5445, 0.6042, 0.6386, 0.5379, 0.5643, 0.1742, 0.3618, 0.3607, 0.3145, 0.446, 0.2238, 0.6349, 0.121, 0.3973, 0.4827, 0.4806, 0.515, 0.4861, 0.6317, 0.4116, 0.6883, 0.6431, 0.3818, 0.4868, 0.6874, 0.53, 0.4227, 0.4311, 0.4187, 0.6068, 0.5641, 0.7207, 0.2247, 0.4967, 0.3395, 0.2176, 0.5134, 0.3712, 0.6381, 0.644, 0.5928, 0.5789, 0.6155, 0.3126, 0.3289, 0.5092, 0.7037, 0.4232, 0.6163, 0.5722, 0.2937, 0.6061, 0.6874, 0.6504, 0.587, 0.5386, 0.6219, 0.1849, 0.5291, 0.1684, 0.1536, 0.3411, 0.4831, 0.5127, 0.3921, 0.2839, 0.4153, 0.4104, 0.5905, 0.4832, 0.494, 0.6689, 0.4588, 0.5707, 0.3587, 0.1782, 0.4404, 0.5853, 0.5058, 0.329, 0.5024, 0.5071, 0.642, 0.6276, 0.4267, 0.6039, 0.4042, 0.3195, 0.3514, 0.4727, 0.4708, 0.4018, 0.3987, 0.6048, 0.5261, 0.571, 0.4171, 0.6731, 0.526, 0.4607, 0.5633, 0.3915, 0.5684, 0.4526, 0.3607, 0.4203, 0.542, 0.2261, 0.5461, 0.4382, 0.3588, 0.4557, 0.2883, 0.5529, 0.4541, 0.4671, 0.3315, 0.4166, 0.4111, 0.5237, 0.5012, 0.308, 0.1222, 0.64, 0.582, 0.6067, 0.5945, 0.3143, 0.3896, 0.5523, 0.6329, 0.5148, 0.1349, 0.6925, 0.3518, 0.7661, 0.7105, 0.4315, 0.4672, 0.4469, 0.3592, 0.5639, 0.4658, 0.6377, 0.5864, 0.4882, 0.4988, 0.5429]\n"
     ]
    }
   ],
   "source": [
    "# channel_list = ['all_C', 'all_O', 'all_N', 'acidic', 'basic', 'polar', 'nonpolar',\\\n",
    "#                 'charged', 'amphipathic','hydrophobic', 'aromatic', 'acceptor', 'donor',\\\n",
    "#                 'ring', 'hyb', 'heavyvalence', 'heterovalence', 'partialcharge','protein', 'ligand']\n",
    "channel_list = ['ligand']\n",
    "#other_filters = np.array(['backbone', 'sidechains'])\n",
    "voxel = voxelize(file_name, channels=channel_list, bin_size=1.0,num_bins=30, ligand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c plotly plotly-orca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "chan = 'ligand'\n",
    "title = 'Ligand'\n",
    "plt.rc('xtick', labelsize=15)\n",
    "\n",
    "#field_dict = make_fields(myprotein_dict[0], channels = [chan], bin_size=1.0,num_bins=50, ligand=True, ligand_dict=myprotein_dict[1])\n",
    "#field_dict = make_fields(myprotein_dict[0], channels = [chan], bin_size=1.0,num_bins=50, ligand=True)\n",
    "field_dict = voxelize(file_name, channels=[chan], bin_size=1.0,num_bins=30, path_type='file', ligand=True)\n",
    "\n",
    "\n",
    "plottable=plot_field_test(field_dict[chan],num_bins=30, show=False, title=title, save=True)\n",
    "# plottable.write_image('test.svg')\n",
    "# plottable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_dict = make_fields(myprotein_dict[0], channels = [chan], bin_size=1.0,num_bins=30, ligand=True, ligand_dict=myprotein_dict[1])\n",
    "\n",
    "from cnns4qspr import visualizer\n",
    "plottable=plot_field_test(field_dict[chan],num_bins=30, bin_size=1.0, show=False)\n",
    "plottable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "import chart_studio.tools as tls\n",
    "\n",
    "username = 'cashraf2'\n",
    "api_key = 'Vtee5Yc5ttj5N8HFnWgr'\n",
    "\n",
    "chart_studio.tools.set_credentials_file(username=username, api_key=api_key)\n",
    "\n",
    "py.plot(plottable, file_name='preotein_ligand', auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smarts_list = [\n",
    "                '[#6+0!$(*~[#7,#8,F]),SH0+0v2,s+0,S^3,Cl+0,Br+0,I+0]',\n",
    "                '[a]',\n",
    "                '[!$([#1,#6,F,Cl,Br,I,o,s,nX3,#7v5,#15v5,#16v4,#16v6,*+1,*+2,*+3])]',\n",
    "                '[!$([#6,H0,-,-2,-3]),$([!H0;#7,#8,#9])]',\n",
    "                '[r]'\n",
    "            ]\n",
    "\n",
    "smart_filters = np.array(['hydrophobic', 'aromatic', 'acceptor', 'donor',\n",
    "                             'ring'])\n",
    "\n",
    "channel = 'ring'\n",
    "# smarts_list[smart_filters==channel)]\n",
    "smarts_list_entry = smarts_list[np.int(np.where(smart_filters == channel)[0])]\n",
    "molecule = next(pybel.readfile('mol2', '1a1e_ligand.mol2'))\n",
    "pattern = pybel.Smarts(smarts_list_entry)\n",
    "atoms_with_prop = np.array(list(*zip(*pattern.findall(molecule))),\n",
    "                                       dtype=int) - 1\n",
    "atoms_with_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../PDBbind/test-set/1a1e/1a1e_ligand.mol2'\n",
    "file_type = path.split('.')[-1]\n",
    "file_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "named_prop = np.array(['hyb', 'heavyvalence', 'heterovalence', 'partialcharge'])\n",
    "\n",
    "channel = 'partialcharge'\n",
    "\n",
    "print(index)\n",
    "prop = []\n",
    "for atom in pocket:\n",
    "    #atom.__getattribute__(prop)\n",
    "    prop.append(atom.__getattribute__(named_prop[np.int(np.where(named_prop == channel)[0])]))\n",
    "\n",
    "prop = np.array(prop)\n",
    "\n",
    "normalized_prop =  (prop-min(prop))/(max(prop)-min(prop))\n",
    "norm_prop = normalized_prop.reshape(73,1)\n",
    "normalized_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This module contains functions to plot atomic density fields before\n",
    "they go into a model, as well as what the density fields have been\n",
    "transformed into at certain points within the model.\n",
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from mpl_toolkits import mplot3d\n",
    "#from cnns4qspr.featurizer import load_cnn\n",
    "\n",
    "def outer_block1_hook(module, input_, output):\n",
    "    global outer_block1_out\n",
    "    outer_block1_out = output\n",
    "\n",
    "\n",
    "def outer_block2_hook(module, input_, output):\n",
    "    global outer_block2_out\n",
    "    outer_block2_out = output\n",
    "\n",
    "\n",
    "def outer_block3_hook(module, input_, output):\n",
    "    global outer_block3_out\n",
    "    outer_block3_out = output\n",
    "\n",
    "\n",
    "def outer_block4_hook(module, input_, output):\n",
    "    global outer_block4_out\n",
    "    outer_block4_out = output\n",
    "\n",
    "\n",
    "def outer_block5_hook(module, input_, output):\n",
    "    global outer_block5_out\n",
    "    outer_block5_out = output\n",
    "\n",
    "def plot_field_test(\n",
    "        field,\n",
    "        num_bins=50,\n",
    "        bin_size=1.0,\n",
    "        color='deep',\n",
    "        threshold=0.2,\n",
    "        alpha=0.7,\n",
    "        show=True,\n",
    "        title='',\n",
    "        save=False):\n",
    "    \"\"\"\n",
    "    This function takes a tensorfield and plots the field density in 3D\n",
    "    space. The field describes an atomic \"density\" at each voxel.\n",
    "\n",
    "    Parameters:\n",
    "        field (pytorch tensor, required): A field from a field\n",
    "            dictionary that was output by\n",
    "            either `voxelize` or `make_fields`.\n",
    "\n",
    "        color (str, optional): The color scheme to plot the field. Any\n",
    "            of the Plotly continuous color schemes. 'deep' and 'ice_r'\n",
    "            are recommended as good baselines.\n",
    "\n",
    "        threshold (float, optional): The threshold intensity that a\n",
    "            voxel must have in order to be included in the plot.\n",
    "\n",
    "        alpha (float, optional): Amount of transparency to use in\n",
    "            plotted marks.\n",
    "\n",
    "        show (boolean, optional): Whether to show the plot. If false,\n",
    "            the plotly fig object is returned.\n",
    "\n",
    "    Returns:\n",
    "        plotly figure object: If show=False, a plotly figure object is\n",
    "        returned\n",
    "    \"\"\"\n",
    "    cube = field.reshape(num_bins, num_bins, num_bins)\n",
    "    #cube /= cube.max()\n",
    "\n",
    "    cubelist = []\n",
    "    xval = np.linspace(-len(cube[0]), len(cube[0]), num_bins)\n",
    "    yval = np.linspace(-len(cube[0]), len(cube[0]), num_bins)\n",
    "    zval = np.linspace(-len(cube[0]), len(cube[0]), num_bins)\n",
    "    \n",
    "    xval = np.linspace(-len(cube[0]) * bin_size / 2.0, len(cube[0]) * bin_size / 2.0, num_bins)\n",
    "    yval = np.linspace(-len(cube[0]) * bin_size / 2.0, len(cube[0]) * bin_size / 2.0, num_bins)\n",
    "    zval = np.linspace(-len(cube[0]) * bin_size / 2.0, len(cube[0]) * bin_size / 2.0, num_bins)\n",
    "    # make a dataframe of x,y,z,intensity for each point in the cube\n",
    "    # to do this have to loop through the cube\n",
    "    for i, xval2 in enumerate(xval):\n",
    "\n",
    "        for j, yval2 in enumerate(yval):\n",
    "\n",
    "            for k, zval2 in enumerate(zval):\n",
    "\n",
    "                cubelist.append([xval2, yval2, zval2, cube[i][j][k]])\n",
    "\n",
    "    cube_df = pd.DataFrame(cubelist, columns=['x', 'y', 'z', 'intensity'])\n",
    "    \n",
    "\n",
    "    # only show the voxels with some intensity\n",
    "    #cube_df = cube_df[cube_df['intensity'] > threshold]\n",
    "    cube_df = cube_df[cube_df['intensity'] != 0]\n",
    "#     fig = px.scatter_3d(cube_df, x='x', y='y', z='z',\n",
    "#                         color='intensity', opacity=alpha,\n",
    "#                         color_continuous_scale='sunsetdark')\n",
    "#     fig.update_layout(\n",
    "#         scene=dict(\n",
    "#             xaxis=dict(range=[-num_bins / 2.0, num_bins / 2.0]),\n",
    "#             yaxis=dict(range=[-num_bins / 2.0, num_bins / 2.0]),\n",
    "#             zaxis=dict(range=[-num_bins / 2.0, num_bins / 2.0])\n",
    "#         ), title=title\n",
    "#     )\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlabel('x', fontsize=30, fontweight='bold')\n",
    "    ax.set_ylabel('y', fontsize=30, fontweight='bold')\n",
    "    ax.set_zlabel('z', fontsize=30, fontweight='bold')\n",
    "    my_cmap = plt.get_cmap('winter')\n",
    "    sctt = ax.scatter3D(cube_df['x'], cube_df['y'], cube_df['z'], alpha=0.8,\n",
    "                        c= cube_df['intensity'], cmap=my_cmap, marker='o', s=40)\n",
    "    cbar = fig.colorbar(sctt, ax=ax, shrink=0.5, aspect=5)\n",
    "    cbar.ax.tick_params(labelsize=25)\n",
    "    ax.set_title(title, fontsize=30, fontweight='bold')\n",
    "#     fig.update_layout(\n",
    "#         scene=dict(\n",
    "#             xaxis=dict(range=[-num_bins / 2.0, num_bins / 2.0]),\n",
    "#             yaxis=dict(range=[-num_bins / 2.0, num_bins / 2.0]),\n",
    "#             zaxis=dict(range=[-num_bins / 2.0, num_bins / 2.0])\n",
    "#         ), title=title\n",
    "#     )\n",
    "    plt.show()\n",
    "    if save==True:\n",
    "        fig.savefig('fig/figure.png', dpi=600)\n",
    "    \n",
    "    if show:\n",
    "        fig.show()\n",
    "        figret = None\n",
    "    else:\n",
    "        figret = fig\n",
    "    return figret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan = 'partialcharge'\n",
    "\n",
    "field_dict = make_fields(myprotein_dict[0], channels = [chan], bin_size=1.0,num_bins=30, ligand=True, ligand_dict=myprotein_dict[1])\n",
    "#field_dict = make_fields(myprotein_dict[0], channels = [chan], bin_size=1.0,num_bins=50, ligand=False)\n",
    "\n",
    "\n",
    "\n",
    "plottable=plot_field_test(field_dict[chan],num_bins=30, show=False)\n",
    "plottable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan = 'acidic'\n",
    "\n",
    "field_dict = make_fields(myprotein_dict[0], channels = [chan], bin_size=1.0,num_bins=50, ligand=True, ligand_dict=myprotein_dict[1])\n",
    "#field_dict = make_fields(myprotein_dict[0], channels = [chan], bin_size=1.0,num_bins=50, ligand=False)\n",
    "\n",
    "\n",
    "plottable=plot_field_test(field_dict[chan],num_bins=50, show=False)\n",
    "plottable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge = np.loadtxt('charge.out')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-5, 10, 1)\n",
    "plt.hist(charge, bins=x)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge[charge >= 3] = 2.9\n",
    "charge[charge < -3] = -3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = charge // charge.std()\n",
    "\n",
    "plt.hist(charge, bins=x)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_positions(grid_array):\n",
    "    \"\"\"\n",
    "    This function returns the 3D meshgrids of x, y and z positions.\n",
    "    These cubes will be flattened, then used as a reference coordinate system\n",
    "    to place the actual channel densities into.\n",
    "    Parameters:\n",
    "        grid_positions (pytorch tensor): lineraly spaced grid\n",
    "    Returns:\n",
    "        array: meshgrid array of the x, y and z positions.\n",
    "    \"\"\"\n",
    "    xgrid = grid_array.view(-1, 1, 1).repeat(1, len(grid_array), len(grid_array))\n",
    "    ygrid = grid_array.view(1, -1, 1).repeat(len(grid_array), 1, len(grid_array))\n",
    "    zgrid = grid_array.view(1, 1, -1).repeat(len(grid_array), len(grid_array), 1)\n",
    "    return (xgrid, ygrid, zgrid)\n",
    "\n",
    "def norm_properties(prop, channel):\n",
    "    \n",
    "    if channel == 'hyb':\n",
    "        max_prop = 3\n",
    "        min_prop = 0\n",
    "    elif channel == 'heterovalence':\n",
    "        max_prop = 4\n",
    "        min_prop = 0\n",
    "    elif channel == 'heavyvalence':\n",
    "        max_prop = 4\n",
    "        min_prop = 0\n",
    "    else:\n",
    "        max_prop = 2.276\n",
    "        min_prop = -1.167\n",
    "        # clamping the charge value within a range\n",
    "        # the range is chosen from ligand data\n",
    "        prop[prop > 2.276] = 2.276\n",
    "        prop[prop < -1.166] = -1.167\n",
    "    \n",
    "    norm_prop = (prop-min_prop)/(max_prop-min_prop)\n",
    "    \n",
    "    return norm_prop\n",
    "\n",
    "def make_fields(protein_dict, channels, bin_size, num_bins, ligand_dict=None, ligand=False):\n",
    "    \"\"\"\n",
    "    This function takes a protein dict (from load_input function) and outputs a\n",
    "        large tensor containing many atomic \"fields\" for the protein.\n",
    "    The fields describe the atomic \"density\" (an exponentially decaying function\n",
    "        of number of atoms in a voxel) of any particular atom type.\n",
    "    Parameters:\n",
    "        protein_dict (dict, requred): dictionary from the load_input function\n",
    "        channels (list-like, optional): the different atomic densities we want fields for\n",
    "            theoretically these different fields provide different chemical information\n",
    "            full list of available channels is in protein_dict['atom_type_set']\n",
    "        bin_size (float, optional): the side-length (angstrom) of a given voxel in the box\n",
    "            that atomic densities are placed in\n",
    "        num_bins (int, optional): how big is the cubic field tensor side length\n",
    "            (i.e., num_bins is box side length)\n",
    "    Returns:\n",
    "        dictionary: A list of atomic density tensors (50x50x50), one for each\n",
    "            channel in channels\n",
    "    \"\"\"\n",
    "    # sets of allowed filters to build channels with\n",
    "    residue_filters = protein_dict['residue_set']\n",
    "    atom_filters = protein_dict['atom_type_set']\n",
    "    general_filters = ['all_C', 'all_O', 'all_N']\n",
    "    residue_property_filters = np.array(['acidic', 'basic', 'polar', 'nonpolar',\\\n",
    "                                         'charged', 'amphipathic'])\n",
    "    smart_filters = np.array(['hydrophobic', 'aromatic', 'acceptor', 'donor',\n",
    "                             'ring'])\n",
    "    named_prop = np.array(['hyb', 'heavyvalence', 'heterovalence', 'partialcharge'])\n",
    "    protein_ligand_filters = np.array(['protein', 'ligand'])\n",
    "    #protein_ligand_filters = np.array(['moltype'])\n",
    "    other_filters = np.array(['backbone', 'sidechains'])\n",
    "\n",
    "    # consolidate into one set of filters\n",
    "    filter_set = {'atom':atom_filters, 'residue':residue_filters,\\\n",
    "                  'residue_property':residue_property_filters, \\\n",
    "                  'smarts_property':smart_filters, \\\n",
    "                  'atom_property': named_prop, 'general': general_filters,\n",
    "                  'protein_ligand': protein_ligand_filters, 'other':other_filters}\n",
    "\n",
    "    # construct a single empty field, then initialize a dictionary with one\n",
    "    # empty field for every channel we are going to calculate the density for\n",
    "    empty_field = torch.zeros(num_bins, num_bins, num_bins).to(device_type)\n",
    "    fields = {channel:empty_field for channel in channels}\n",
    "\n",
    "    # create linearly spaced grid (default is -49 to 49 in steps of 2)\n",
    "    grid_1d = torch.linspace(start=-num_bins / 2 * bin_size + bin_size / 2,\n",
    "                             end=num_bins / 2 * bin_size - bin_size / 2,\n",
    "                             steps=num_bins).to(device_type)\n",
    "\n",
    "    # This makes three 3D meshgrids in for the x, y, and z positions\n",
    "    # These cubes will be flattened, then used as a reference coordinate system\n",
    "    # to place the actual channel densities into\n",
    "    xgrid, ygrid, zgrid = grid_positions(grid_1d)\n",
    "\n",
    "    for channel_index, channel in enumerate(channels):\n",
    "        #print(channel)\n",
    "\n",
    "        # no illegal channels allowed, assume the channel sucks\n",
    "        channel_allowed = check_channel(channel, filter_set)\n",
    "\n",
    "        if channel_allowed:\n",
    "            pass\n",
    "        else:\n",
    "            #err_string = 'Allowed channels are: in a protein\\'s atom_type_set,\n",
    "                        # residue_set',or the \\'sidechains\\' and \\'backbone\\' channels.'\n",
    "            raise ValueError('The channel ', channel, ' is not allowed for this protein.')\n",
    "\n",
    "\n",
    "        # Extract positions of atoms that are part of the current channel\n",
    "\n",
    "        atom_positions_protein = find_channel_atoms(channel, protein_dict, filter_set)\n",
    "        \n",
    "        \n",
    "        if ligand == True:\n",
    "            atom_positions_ligand = find_channel_atoms(channel, ligand_dict, filter_set)\n",
    "            \n",
    "            if channel == 'protein':\n",
    "                    atom_positions = atom_positions_protein\n",
    "        \n",
    "            elif channel == 'ligand':\n",
    "                    atom_positions = atom_positions_ligand\n",
    "            else:\n",
    "                atom_positions = np.concatenate((atom_positions_protein, atom_positions_ligand))\n",
    "            #print(atom_positions_protein.shape)\n",
    "        else:\n",
    "            atom_positions = atom_positions_protein\n",
    "        #print(atom_positions.shape)\n",
    "            \n",
    "        \n",
    "        #print('This is channel ', atom_positions)\n",
    "\n",
    "        atom_positions = torch.FloatTensor(atom_positions).to(device_type)\n",
    "        \n",
    "\n",
    "        # xgrid.view(-1, 1) is 125,000 long, because it's viewing a 50x50x50 cube in one column\n",
    "        # then you repeat that column horizontally for each atom\n",
    "        xx_xx = xgrid.view(-1, 1).repeat(1, len(atom_positions))\n",
    "        yy_yy = ygrid.view(-1, 1).repeat(1, len(atom_positions))\n",
    "        zz_zz = zgrid.view(-1, 1).repeat(1, len(atom_positions))\n",
    "        \n",
    "        # at this point we've created 3 arrays that are 125,000 long\n",
    "        # and as wide as the number of atoms that are the current channel type\n",
    "        # these 3 arrays just contain the flattened x,y,z positions of our 50x50x50 box\n",
    "\n",
    "\n",
    "        # now do the same thing as above, just with the ACTUAL atomic position data\n",
    "        posx_posx = atom_positions[:, 0].contiguous().view(1, -1).repeat(len(xgrid.view(-1)), 1)\n",
    "        posy_posy = atom_positions[:, 1].contiguous().view(1, -1).repeat(len(ygrid.view(-1)), 1)\n",
    "        posz_posz = atom_positions[:, 2].contiguous().view(1, -1).repeat(len(zgrid.view(-1)), 1)\n",
    "        # three tensors of the same size, with actual atomic coordinates\n",
    "\n",
    "        # normalizes the atomic positions with respect to the center of the box\n",
    "        # and calculates density of atoms in each voxel\n",
    "        \n",
    "        bin_size = torch.tensor(float(bin_size)).to(device_type)\n",
    "        sigma = 0.5*bin_size\n",
    "\n",
    "        \n",
    "        if channel in named_prop:\n",
    "            prop = []\n",
    "            for atom in protein_dict['smarts']:\n",
    "    #atom.__getattribute__(prop)\n",
    "                prop.append(atom.__getattribute__(named_prop[np.int(np.where(named_prop == channel)[0])]))\n",
    "            \n",
    "            if ligand == True:\n",
    "                for atom in ligand_dict['smarts']:\n",
    "    #atom.__getattribute__(prop)\n",
    "                    prop.append(atom.__getattribute__(named_prop[np.int(np.where(named_prop == channel)[0])]))\n",
    "                \n",
    "            prop = np.array(prop)\n",
    "\n",
    "            normalized_prop =  norm_properties(prop, channel)\n",
    "            normalized_prop =  torch.FloatTensor(normalized_prop).to(device_type)\n",
    "            #print(normalized_prop)\n",
    "            if channel == 'partialcharge':\n",
    "                rev_std = 2.90\n",
    "                prop = prop + 3.0\n",
    "                \n",
    "                prop = np.divide(prop, 0.3448)\n",
    "            prop =  torch.FloatTensor(prop).to(device_type)\n",
    "            print(prop.max())\n",
    "            \n",
    "            print(normalized_prop.max())\n",
    "            density = torch.exp(-(((xx_xx - posx_posx)**2) \n",
    "                              + ((yy_yy - posy_posy)**2)\n",
    "                              + ((zz_zz - posz_posz)**2)) * prop / (2 * (sigma)**2)\n",
    "                              )\n",
    "            print(density.max())\n",
    "        else:\n",
    "            density = torch.exp(-((xx_xx - posx_posx)**2\n",
    "                            + (yy_yy - posy_posy)**2\n",
    "                            + (zz_zz - posz_posz)**2) / (2 * (sigma)**2))\n",
    "        \n",
    "\n",
    "        # Normalize so each atom density sums to one\n",
    "        density /= torch.sum(density, dim=0)\n",
    "\n",
    "        # Sum densities and reshape to original shape\n",
    "        sum_densities = torch.sum(density, dim=1).view(xgrid.shape)\n",
    "        print(sum_densities.shape)\n",
    "        print(density.shape)\n",
    "\n",
    "        # set all nans to 0\n",
    "        sum_densities[sum_densities != sum_densities] = 0\n",
    "\n",
    "        # add two empty dimmensions to make it 1x1x50x50x50, needed for CNN\n",
    "        # sum_densities = sum_densities.unsqueeze(0)\n",
    "        # sum_densities = sum_densities.unsqueeze(0)\n",
    "\n",
    "        #fields[atom_type_index] = sum_densities\n",
    "        fields[channel] = sum_densities.numpy()\n",
    "\n",
    "#     if return_bins:\n",
    "#         return fields, num_bins\n",
    "#     else:\n",
    "    return fields\n",
    "\n",
    "def check_channel(channel, filter_set):\n",
    "    \"\"\"\n",
    "    This function checks to see if a channel the user is asking to make a field\n",
    "        for is an allowed channel to ask for.\n",
    "    Parameters:\n",
    "        channel (str, required): The atomic channel being requested\n",
    "        filter_set (dict, required): The set of defined atomic filters\n",
    "    Returns:\n",
    "        boolean: indicator for if the channel is allowed\n",
    "    \"\"\"\n",
    "    channel_allowed = False\n",
    "    for key in filter_set:\n",
    "        if channel in filter_set[key]:\n",
    "            channel_allowed = True\n",
    "\n",
    "    return channel_allowed\n",
    "\n",
    "def find_channel_atoms(channel, protein_dict, filter_set):\n",
    "    \"\"\"\n",
    "    This function finds the coordinates of all relevant atoms in a channel.\n",
    "    It uses the filter set to constrcut the atomic channel (i.e., a channel can\n",
    "        be composed of multiple filters).\n",
    "    Parameters:\n",
    "        channel (str, required): The atomic channel being constructed\n",
    "        protein_dict (dict, required): The dictionary of the protein, returned from\n",
    "            load_input()\n",
    "        filter_set (dict, required): The set of available filters to construct channels with\n",
    "    Returns:\n",
    "        numpy array:  array containing the coordinates of each atom that is relevant\n",
    "            to the channel\n",
    "    \"\"\"\n",
    "    if channel in filter_set['atom']:\n",
    "        atom_positions = protein_dict['shifted_positions'][protein_dict['atom_types'] == channel]\n",
    "    \n",
    "    \n",
    "    elif channel in filter_set['general']:\n",
    "        atom_dict = {'all_C' :'C', 'all_O' : 'O', 'all_N' : 'N'}\n",
    "        atom_positions = protein_dict['shifted_positions']\\\n",
    "                        [[a.startswith(atom_dict[channel], 0) for a in protein_dict['atom_types']]]\n",
    "\n",
    "    elif channel in filter_set['residue']:\n",
    "        atom_positions = protein_dict['shifted_positions'][protein_dict['residues'] == channel]\n",
    "        \n",
    "    elif channel in filter_set['smarts_property']:\n",
    "        smarts_list = [\n",
    "                '[#6+0!$(*~[#7,#8,F]),SH0+0v2,s+0,S^3,Cl+0,Br+0,I+0]',\n",
    "                '[a]',\n",
    "                '[!$([#1,#6,F,Cl,Br,I,o,s,nX3,#7v5,#15v5,#16v4,#16v6,*+1,*+2,*+3])]',\n",
    "                '[!$([#6,H0,-,-2,-3]),$([!H0;#7,#8,#9])]',\n",
    "                '[r]'\n",
    "            ]\n",
    "        smarts_list_entry = smarts_list[np.int(np.where(filter_set['smarts_property'] == channel)[0])]\n",
    "        pattern = pybel.Smarts(smarts_list_entry)\n",
    "        atoms_smart = np.array(list(*zip(*pattern.findall(protein_dict['smarts']))),\n",
    "                                    dtype=int) - 1\n",
    "        #print(atoms_smart)\n",
    "        atom_positions = protein_dict['shifted_positions'][atoms_smart]\n",
    "    \n",
    "    elif channel in filter_set['atom_property']:\n",
    "        atom_positions = protein_dict['shifted_positions']\n",
    "        \n",
    "    elif channel in filter_set['protein_ligand']:\n",
    "        atom_positions = protein_dict['shifted_positions']\n",
    "\n",
    "    elif channel in filter_set['other']: # backbone or sidechain\n",
    "        if channel == 'backbone':\n",
    "            # create boolean arrays for backbone atoms\n",
    "            bool_oxygen = protein_dict['atom_types'] == 'O'\n",
    "            bool_carbon = protein_dict['atom_types'] == 'C'\n",
    "            bool_alphacarbon = protein_dict['atom_types'] == 'CA'\n",
    "            bool_nitrogen = protein_dict['atom_types'] == 'N'\n",
    "\n",
    "            # sum of all the backbone channels into one boolean array\n",
    "            bool_backbone = bool_oxygen + bool_carbon + bool_alphacarbon + bool_nitrogen\n",
    "\n",
    "            # select the backbone atoms\n",
    "            atom_positions = protein_dict['shifted_positions'][bool_backbone]\n",
    "\n",
    "        else: # it was 'sidechain' filter, so grab sidechain atoms\n",
    "            backbone_atom_set = np.array(['O', 'C', 'CA', 'N'])\n",
    "            sidechain_atom_set = np.array([atom for atom in protein_dict['atom_type_set'] \\\n",
    "                                           if atom not in backbone_atom_set])\n",
    "\n",
    "            for index, sidechain_atom in enumerate(sidechain_atom_set):\n",
    "                if index == 0:\n",
    "                    # create the first sidechains boolean array, will be edited\n",
    "                    bool_sidechains = protein_dict['atom_types'] == sidechain_atom\n",
    "                else:\n",
    "                    # single boolean array for the current sidechain atom\n",
    "                    bool_atom = protein_dict['atom_types'] == sidechain_atom\n",
    "\n",
    "                    # sum this boolean array with the master boolean array\n",
    "                    bool_sidechains += bool_atom\n",
    "\n",
    "            # grab all sidechain atom positions\n",
    "            atom_positions = protein_dict['shifted_positions'][bool_sidechains]\n",
    "\n",
    "    else: # it was a residue property channel\n",
    "        acidic_residues = np.array(['ASP', 'GLU'])\n",
    "        basic_residues = np.array(['LYS', 'ARG', 'HIS'])\n",
    "        polar_residues = np.array(['GLN', 'ASN', 'HIS', 'SER', 'THR', 'TYR', 'CYS'])\n",
    "        nonpolar_residues = np.array(['GLY', 'ALA', 'VAL', 'LEU', \\\n",
    "                                        'ILE', 'MET', 'PRO', 'PHE', 'TRP'])\n",
    "        amphipathic_residues = np.array(['TRP', 'TYR', 'MET'])\n",
    "        charged_residues = np.array(['ARG', 'LYS', 'ASP', 'GLU'])\n",
    "        # custom_residues = something\n",
    "        property_dict = {'acidic':acidic_residues, 'basic':basic_residues,\\\n",
    "                         'polar':polar_residues, 'nonpolar':nonpolar_residues,\\\n",
    "                         'amphipathic':amphipathic_residues, 'charged':charged_residues}\n",
    "\n",
    "        atom_positions = atoms_from_residues(protein_dict, property_dict[channel])\n",
    "\n",
    "    return atom_positions\n",
    "\n",
    "def atoms_from_residues(protein_dict, residue_list):\n",
    "    \"\"\"\n",
    "    This function finds all the atoms in a protein that are members of any residues\n",
    "    in a list of residues.\n",
    "    Parameters:\n",
    "        protein_dict (dict, required): The dictionary of the protein, returned from\n",
    "            load_input()\n",
    "        residue_list (list-like, required): The list of residues whose atoms we are\n",
    "            finding coordinates for\n",
    "    \"\"\"\n",
    "    # construct the appropriate boolean array to index the atoms in the protein_dict\n",
    "    for index, residue in enumerate(residue_list):\n",
    "        if index == 0:\n",
    "            bool_residue = protein_dict['residues'] == residue\n",
    "        else:\n",
    "            bool_residue += protein_dict['residues'] == residue\n",
    "\n",
    "    atom_positions = protein_dict['shifted_positions'][bool_residue]\n",
    "\n",
    "    return atom_positions\n",
    "\n",
    "def voxelize(path, channels=['CA'], path_type='file', ligand=False, bin_size=2.0, num_bins=50, save=False, save_fn='voxels.npy', save_path='./'):\n",
    "    \"\"\"\n",
    "    This function creates a dictionary of tensor fields directly from a pdb file.\n",
    "    These tensor fields can be plotted, or sent directly into the cnn for\n",
    "        plotting internals, or sent all the way through a cnn/vae to be used for\n",
    "        training.\n",
    "    Parameters:\n",
    "        path (str, required): path to a .pdb file\n",
    "        channels (list of strings, optional): The list of atomic channels to be included in\n",
    "            the output dictionary, one field for every channel.\n",
    "            Any channels from points 1-4 below may be combined in any order.\n",
    "            i.e., one could call voxelize with the channels parameter as\n",
    "            channels=['charged', 'CB', 'GLY', 'polar', ...etc]. Note that voxelization\n",
    "            for channels containing more atoms will take longer.\n",
    "            1. any of the following atom types\n",
    "                ['C' 'CA' 'CB' 'CD' 'CD1' 'CD2' 'CE' 'CE1' 'CE2' 'CE3' 'CG' 'CG1' 'CG2'\n",
    "                'CH2' 'CZ' 'CZ2' 'CZ3' 'N' 'ND1' 'ND2' 'NE' 'NE1' 'NE2' 'NH1' 'NH2' 'NZ'\n",
    "                'O' 'OD1' 'OD2' 'OE1' 'OE2' 'OG' 'OG1' 'OH' 'OXT' 'SD' 'SG']\n",
    "            2. Any canonical residue in the protein, using the three letter residue code, all caps\n",
    "               (NOTE: the residue must actually exist in the protein)\n",
    "                e.g., ['LYS', 'LEU', 'ALA']\n",
    "            3. The 'other' channel options: 'backbone', 'sidechains'\n",
    "            4. There are 6 channels corresponding to specific types of residues:\n",
    "                'charged', 'polar', 'nonpolar', 'amphipathic', 'acidic', 'basic'\n",
    "    Returns:\n",
    "        dictionary: a dictionary containing a voxelized atomic fields, one for each\n",
    "        channel requested. Each field has shape = ([1, 1, 50, 50, 50])\n",
    "    \"\"\"\n",
    "    if path_type == 'file':\n",
    "        pro_dict = load_input(path, ligand=ligand)\n",
    "        if ligand == True:\n",
    "            protein_dict = pro_dict[0]\n",
    "            ligand_dict = pro_dict[1]\n",
    "            return make_fields(protein_dict, channels=channels, bin_size=bin_size, num_bins=num_bins, ligand=True, ligand_dict=ligand_dict)\n",
    "        else:\n",
    "            protein_dict = pro_dict\n",
    "            sys.stdout.write('done')\n",
    "            return make_fields(protein_dict, channels=channels, bin_size=bin_size, num_bins=num_bins)\n",
    "\n",
    "    # ------------FOLDER FUNCTIONALITY INCOMPLETE---------------\n",
    "    elif path_type == 'folder':\n",
    "        fields = []\n",
    "        pdb_fns = os.listdir(path)\n",
    "        for j, fn in enumerate(pdb_fns):\n",
    "            progress = '{}/{} pdbs voxelized ({}%)'.format(j, len(pdb_fns), \\\n",
    "                        round(j / len(pdb_fns) * 100, 2))\n",
    "            sys.stdout.write('\\r'+progress)\n",
    "            protein_dict = load_input(os.path.join(path, fn))\n",
    "            field, bins = make_fields(protein_dict, channels=channels, bin_size=bin_size, num_bins=num_bins)\n",
    "            channel_list = []\n",
    "            for channel in channels:\n",
    "                channel_list.append(field[channel].reshape(1,\n",
    "                                                           bins,\n",
    "                                                           bins,\n",
    "                                                           bins))\n",
    "            field = np.concatenate(channel_list).reshape(1,len(channels),\n",
    "                                                         bins, bins, bins)\n",
    "            fields.append(field)\n",
    "        sys.stdout.write(\"\\r\\033[K\")\n",
    "        out_statement = 'voxelization complete!\\n'\n",
    "        sys.stdout.write('\\r'+out_statement)\n",
    "        fields = np.concatenate(fields)\n",
    "\n",
    "        if save:\n",
    "            np.save(os.path.join(save_path, save_fn), fields)\n",
    "        else:\n",
    "            return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnns4qspr",
   "language": "python",
   "name": "cnns4qspr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
