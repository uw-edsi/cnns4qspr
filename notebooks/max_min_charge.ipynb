{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains functions for loading a pdb file and calculating\n",
    "the atomic density fields for different atom types. The fields can then be\n",
    "used for plotting, or to send into the convolutional neural network.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from biopandas.pdb import PandasPdb\n",
    "from biopandas.mol2 import PandasMol2\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pybel\n",
    "from math import ceil, sin, cos, sqrt, pi\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 -5.0\n"
     ]
    }
   ],
   "source": [
    "max_charge = []\n",
    "min_charge = []\n",
    "file_name = []\n",
    "\n",
    "# for filename in os.listdir('./pocket_mol2'):\n",
    "#     mol = PandasMol2().read_mol2('./pocket_mol2/' + filename)\n",
    "#     partial_charge = mol.df['charge'].values\n",
    "    \n",
    "    \n",
    "#     max_charge.append(np.max(partial_charge))\n",
    "#     min_charge.append(np.min(partial_charge))\n",
    "\n",
    "for filename in os.listdir('./ligand_mol2'):\n",
    "\n",
    "    mol = PandasMol2().read_mol2('./ligand_mol2/' + filename)\n",
    "    \n",
    "    partial_charge = mol.df['charge'].values\n",
    "    \n",
    "    file_name.append(filename)\n",
    "    max_charge.append(np.max(partial_charge))\n",
    "    min_charge.append(np.min(partial_charge))\n",
    "\n",
    "\n",
    "max_test = np.max(max_charge)\n",
    "min_test = np.min(min_charge)\n",
    "print(max_test, min_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5zeq_ligand.mol2 3p44_ligand.mol2\n"
     ]
    }
   ],
   "source": [
    "minpos = min_charge.index(min(min_charge))\n",
    "maxpos = max_charge.index(max(max_charge))\n",
    "\n",
    "\n",
    "\n",
    "max_file = file_name[maxpos]\n",
    "min_file = file_name[minpos]\n",
    "\n",
    "print(min_file, max_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "file_exclude = []\n",
    "\n",
    "for i, (a, b) in enumerate(zip(min_charge, max_charge)):\n",
    "    \n",
    "    \n",
    "    if a < -1.167 or b > 2.276:\n",
    "        file_exclude.append(file_name[i])\n",
    "        j = j+1\n",
    "#         print(file_name[i])\n",
    "#     if b > 2.276:\n",
    "#         j = j+1\n",
    "        #print(file_name[i])\n",
    "        \n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6dud_ligand.mol2',\n",
       " '5tg7_ligand.mol2',\n",
       " '5u48_ligand.mol2',\n",
       " '5waf_ligand.mol2',\n",
       " '3vjt_ligand.mol2',\n",
       " '4u0x_ligand.mol2',\n",
       " '3sl1_ligand.mol2',\n",
       " '4qvl_ligand.mol2',\n",
       " '2y4a_ligand.mol2',\n",
       " '2jld_ligand.mol2',\n",
       " '5tgy_ligand.mol2',\n",
       " '4hww_ligand.mol2',\n",
       " '3fkv_ligand.mol2',\n",
       " '4wkv_ligand.mol2',\n",
       " '5fqb_ligand.mol2',\n",
       " '4q3s_ligand.mol2',\n",
       " '3zju_ligand.mol2',\n",
       " '4iu0_ligand.mol2',\n",
       " '4daw_ligand.mol2',\n",
       " '3o86_ligand.mol2',\n",
       " '5w14_ligand.mol2',\n",
       " '3nzi_ligand.mol2',\n",
       " '4qw1_ligand.mol2',\n",
       " '3mnu_ligand.mol2',\n",
       " '3way_ligand.mol2',\n",
       " '3mmr_ligand.mol2',\n",
       " '3ixg_ligand.mol2',\n",
       " '2cfd_ligand.mol2',\n",
       " '5agj_ligand.mol2',\n",
       " '4wyy_ligand.mol2',\n",
       " '3cst_ligand.mol2',\n",
       " '4i60_ligand.mol2',\n",
       " '5ne1_ligand.mol2',\n",
       " '2y59_ligand.mol2',\n",
       " '1lpg_ligand.mol2',\n",
       " '6d1m_ligand.mol2',\n",
       " '1sqa_ligand.mol2',\n",
       " '5zeq_ligand.mol2',\n",
       " '1k1i_ligand.mol2',\n",
       " '4kai_ligand.mol2',\n",
       " '3zp9_ligand.mol2',\n",
       " '4qvv_ligand.mol2',\n",
       " '5wac_ligand.mol2',\n",
       " '6rsa_ligand.mol2',\n",
       " '2y2h_ligand.mol2',\n",
       " '4len_ligand.mol2',\n",
       " '5nxx_ligand.mol2',\n",
       " '4wz5_ligand.mol2',\n",
       " '5u4e_ligand.mol2',\n",
       " '1o5b_ligand.mol2',\n",
       " '5u4f_ligand.mol2',\n",
       " '4ob0_ligand.mol2',\n",
       " '4i06_ligand.mol2',\n",
       " '1owh_ligand.mol2',\n",
       " '2zda_ligand.mol2',\n",
       " '2y2k_ligand.mol2',\n",
       " '2xni_ligand.mol2',\n",
       " '4lv3_ligand.mol2',\n",
       " '3pup_ligand.mol2',\n",
       " '3mxr_ligand.mol2',\n",
       " '2ydm_ligand.mol2',\n",
       " '3q4c_ligand.mol2',\n",
       " '5w12_ligand.mol2',\n",
       " '4ie2_ligand.mol2',\n",
       " '5agi_ligand.mol2',\n",
       " '2cfg_ligand.mol2',\n",
       " '2xln_ligand.mol2',\n",
       " '5fq9_ligand.mol2',\n",
       " '3e9b_ligand.mol2',\n",
       " '4qwu_ligand.mol2',\n",
       " '1esz_ligand.mol2',\n",
       " '5lc0_ligand.mol2',\n",
       " '5ags_ligand.mol2',\n",
       " '3zjv_ligand.mol2',\n",
       " '4no1_ligand.mol2',\n",
       " '1c5z_ligand.mol2',\n",
       " '3p3h_ligand.mol2',\n",
       " '4qvy_ligand.mol2',\n",
       " '4wku_ligand.mol2',\n",
       " '4jfw_ligand.mol2',\n",
       " '3mg0_ligand.mol2',\n",
       " '5fom_ligand.mol2',\n",
       " '3fxz_ligand.mol2',\n",
       " '3whw_ligand.mol2',\n",
       " '5u4c_ligand.mol2',\n",
       " '5dhf_ligand.mol2',\n",
       " '3p55_ligand.mol2',\n",
       " '4qvp_ligand.mol2',\n",
       " '5wae_ligand.mol2',\n",
       " '5tg4_ligand.mol2',\n",
       " '2y2n_ligand.mol2',\n",
       " '5nxy_ligand.mol2',\n",
       " '4ob2_ligand.mol2',\n",
       " '1oyt_ligand.mol2',\n",
       " '3rj7_ligand.mol2',\n",
       " '4wz4_ligand.mol2',\n",
       " '4l6q_ligand.mol2',\n",
       " '3tdz_ligand.mol2',\n",
       " '4lv1_ligand.mol2',\n",
       " '2y2i_ligand.mol2',\n",
       " '4qvw_ligand.mol2',\n",
       " '4jhq_ligand.mol2',\n",
       " '3bwf_ligand.mol2',\n",
       " '4iu4_ligand.mol2',\n",
       " '6ceh_ligand.mol2',\n",
       " '4xuz_ligand.mol2',\n",
       " '6d1l_ligand.mol2',\n",
       " '3bho_ligand.mol2',\n",
       " '5agt_ligand.mol2',\n",
       " '3wax_ligand.mol2',\n",
       " '1o3f_ligand.mol2',\n",
       " '2xk1_ligand.mol2',\n",
       " '3gy4_ligand.mol2',\n",
       " '4qw0_ligand.mol2',\n",
       " '3o87_ligand.mol2',\n",
       " '4ixu_ligand.mol2',\n",
       " '2wfg_ligand.mol2',\n",
       " '5fjw_ligand.mol2',\n",
       " '3mke_ligand.mol2',\n",
       " '3p3j_ligand.mol2',\n",
       " '3zjt_ligand.mol2',\n",
       " '4q3r_ligand.mol2',\n",
       " '5ee8_ligand.mol2',\n",
       " '5fqc_ligand.mol2',\n",
       " '3m1s_ligand.mol2',\n",
       " '5u4a_ligand.mol2',\n",
       " '4qvm_ligand.mol2',\n",
       " '3sl0_ligand.mol2',\n",
       " '3utu_ligand.mol2',\n",
       " '5wag_ligand.mol2',\n",
       " '5tg6_ligand.mol2',\n",
       " '2z3z_ligand.mol2',\n",
       " '2xdm_ligand.mol2',\n",
       " '4kb7_ligand.mol2',\n",
       " '5hja_ligand.mol2',\n",
       " '3bm6_ligand.mol2',\n",
       " '2xcn_ligand.mol2',\n",
       " '5j8x_ligand.mol2',\n",
       " '3skk_ligand.mol2',\n",
       " '4hxq_ligand.mol2',\n",
       " '5tg5_ligand.mol2',\n",
       " '4qvq_ligand.mol2',\n",
       " '5wad_ligand.mol2',\n",
       " '4u5t_ligand.mol2',\n",
       " '6c8x_ligand.mol2',\n",
       " '3fy0_ligand.mol2',\n",
       " '5vrl_ligand.mol2',\n",
       " '5hj9_ligand.mol2',\n",
       " '4qvn_ligand.mol2',\n",
       " '5hlm_ligand.mol2',\n",
       " '2y2p_ligand.mol2',\n",
       " '6hx5_ligand.mol2',\n",
       " '4q3q_ligand.mol2',\n",
       " '4jfv_ligand.mol2',\n",
       " '3mkf_ligand.mol2',\n",
       " '4qw3_ligand.mol2',\n",
       " '3eyd_ligand.mol2',\n",
       " '5eec_ligand.mol2',\n",
       " '4ixv_ligand.mol2',\n",
       " '5agr_ligand.mol2',\n",
       " '4m1j_ligand.mol2',\n",
       " '2eep_ligand.mol2',\n",
       " '3sjt_ligand.mol2',\n",
       " '6da4_ligand.mol2',\n",
       " '5t66_ligand.mol2',\n",
       " '1k2v_ligand.mol2',\n",
       " '3p44_ligand.mol2',\n",
       " '3e6k_ligand.mol2',\n",
       " '4ie3_ligand.mol2',\n",
       " '5w13_ligand.mol2',\n",
       " '3vjs_ligand.mol2',\n",
       " '5fsb_ligand.mol2',\n",
       " '5inh_ligand.mol2',\n",
       " '2y2j_ligand.mol2',\n",
       " '3mxs_ligand.mol2',\n",
       " '4lv2_ligand.mol2',\n",
       " '6hwz_ligand.mol2',\n",
       " '5u4g_ligand.mol2',\n",
       " '4kbi_ligand.mol2',\n",
       " '2wq4_ligand.mol2',\n",
       " '4hze_ligand.mol2',\n",
       " '2yak_ligand.mol2',\n",
       " '4ob1_ligand.mol2',\n",
       " '3o88_ligand.mol2']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdb(path):\n",
    "    \"\"\"\n",
    "    Loads all of the atomic positioning/type arrays from a pdb file.\n",
    "    The arrays can then be transformed into density (or \"field\") tensors before\n",
    "        being sent through the neural network.\n",
    "    Parameters:\n",
    "        path (str, required): The full path to the pdb file being voxelized.\n",
    "    Returns:\n",
    "        dictionary: A dictionary containing the following arrays from\n",
    "            the pdb file: num_atoms, atom_types, positions, atom_type_set,\n",
    "            xcoords, ycoords, zcoords, residues, residue_set\n",
    "    \"\"\"\n",
    "    \n",
    "    file_type = path.split('.')[-1]\n",
    "    \n",
    "    if file_type == 'pdb':\n",
    "    #pdb = PandasPdb().read_pdb(path)\n",
    "        pdb = PandasPdb().read_pdb(path)\n",
    "    # This just creates a dataframe from the pdb file using biopandas\n",
    "    #print('This is vars',vars(pdb))\n",
    "        pdf = pdb.df['ATOM']\n",
    "        x_coords = pdf['x_coord'].values\n",
    "        y_coords = pdf['y_coord'].values\n",
    "        z_coords = pdf['z_coord'].values\n",
    "        atom_types = pdf['atom_name'].values\n",
    "        residue_names = pdf['residue_name'].values\n",
    "    \n",
    "    elif file_type == 'mol2':\n",
    "        mol = PandasMol2().read_mol2(path)\n",
    "        pdf = mol\n",
    "        x_coords = pdf.df['x'].values\n",
    "        y_coords = pdf.df['y'].values\n",
    "        z_coords = pdf.df['z'].values\n",
    "        atom_types = pdf.df['atom_name'].values\n",
    "        residue_names = pdf.df['subst_name'].values\n",
    "        partial_charge = pdf.df['charge'].values\n",
    "        smarts_notation = next(pybel.readfile(file_type, path))\n",
    "    else:\n",
    "        raise ValueError('Need a pdb or mol2 file')\n",
    "    # atomic coordinates\n",
    "   \n",
    "\n",
    "    # create an array containing tuples of x,y,z for every atom\n",
    "    positions = []\n",
    "    for i, x in enumerate(x_coords):\n",
    "        position_tuple = (x_coords[i], y_coords[i], z_coords[i])\n",
    "        positions.append(position_tuple)\n",
    "    positions = np.array(positions)\n",
    "\n",
    "    # names of all the atoms contained in the protein\n",
    "    \n",
    "    num_atoms = len(atom_types)\n",
    "    atom_type_set = np.unique(atom_types)\n",
    "    num_atom_types = len(atom_type_set)\n",
    "\n",
    "    # residue names\n",
    "    \n",
    "    residue_set = np.unique(residue_names)\n",
    "\n",
    "    protein_dict = {'x_coords':x_coords, 'y_coords':y_coords, 'z_coords':z_coords,\n",
    "                    'positions':positions, 'atom_types':atom_types,\n",
    "                    'num_atoms':num_atoms, 'atom_type_set':atom_type_set,\n",
    "                    'num_atom_types':num_atom_types, 'residues':residue_names,\n",
    "                    'residue_set':residue_set}\n",
    "    \n",
    "    if file_type == 'mol2':\n",
    "        protein_dict['charge'] = partial_charge\n",
    "        protein_dict['smarts'] = smarts_notation\n",
    "\n",
    "    # add a value to the dictionary, which is all of the atomic coordinates just\n",
    "    # shifted to the origin\n",
    "    protein_dict = shift_coords(protein_dict)\n",
    "\n",
    "    return protein_dict\n",
    "\n",
    "def shift_coords(protein_dict):\n",
    "    \"\"\"\n",
    "    This function shifts the coordinates of a protein so that it's coordinates are in the center\n",
    "    of the field tensor.\n",
    "    Parameters:\n",
    "        protein_dict (dict): A dictionary of information from the first part of the load_pdb function.\n",
    "    Returns:\n",
    "        dictionary: The original protein dict but with an added value containing\n",
    "            the coordinates of the protein shifted to the origin.\n",
    "    \"\"\"\n",
    "    # find the extreme x, y, and z values that exist in the protein atomic coordinates\n",
    "    x_extremes = np.array([protein_dict['x_coords'].min(), protein_dict['x_coords'].max()])\n",
    "    y_extremes = np.array([protein_dict['y_coords'].min(), protein_dict['y_coords'].max()])\n",
    "    z_extremes = np.array([protein_dict['z_coords'].min(), protein_dict['z_coords'].max()])\n",
    "\n",
    "    # calculate the midpoints of the extremes\n",
    "    midpoints = [np.sum(x_extremes)/2, np.sum(y_extremes)/2, np.sum(z_extremes)/2]\n",
    "#     print(x_extremes, y_extremes, z_extremes)\n",
    "\n",
    "    # shift the coordinates by the midpoints of those extremes (center the protein on the origin)\n",
    "    protein_dict['shifted_positions'] = protein_dict['positions'] - midpoints\n",
    "\n",
    "    return protein_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C(=O)(C)N[C@H](C(=O)N[C@H](C(=O)N1CCC[C@H](C1)CCCC)CCC(=O)O)Cc1ccc(cc1)OP(O)(O)O\t1a1e_ligand\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pro_dict = load_pdb('1a1e_ligand.mol2')\n",
    "print(pro_dict['smarts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_positions(grid_array):\n",
    "    \"\"\"\n",
    "    This function returns the 3D meshgrids of x, y and z positions.\n",
    "    These cubes will be flattened, then used as a reference coordinate system\n",
    "    to place the actual channel densities into.\n",
    "    Parameters:\n",
    "        grid_positions (pytorch tensor): lineraly spaced grid\n",
    "    Returns:\n",
    "        array: meshgrid array of the x, y and z positions.\n",
    "    \"\"\"\n",
    "    xgrid = grid_array.view(-1, 1, 1).repeat(1, len(grid_array), len(grid_array))\n",
    "    ygrid = grid_array.view(1, -1, 1).repeat(len(grid_array), 1, len(grid_array))\n",
    "    zgrid = grid_array.view(1, 1, -1).repeat(len(grid_array), len(grid_array), 1)\n",
    "    return (xgrid, ygrid, zgrid)\n",
    "\n",
    "def make_fields(protein_dict, channels, bin_size, num_bins):\n",
    "    \"\"\"\n",
    "    This function takes a protein dict (from load_pdb function) and outputs a\n",
    "        large tensor containing many atomic \"fields\" for the protein.\n",
    "    The fields describe the atomic \"density\" (an exponentially decaying function\n",
    "        of number of atoms in a voxel) of any particular atom type.\n",
    "    Parameters:\n",
    "        protein_dict (dict, requred): dictionary from the load_pdb function\n",
    "        channels (list-like, optional): the different atomic densities we want fields for\n",
    "            theoretically these different fields provide different chemical information\n",
    "            full list of available channels is in protein_dict['atom_type_set']\n",
    "        bin_size (float, optional): the side-length (angstrom) of a given voxel in the box\n",
    "            that atomic densities are placed in\n",
    "        num_bins (int, optional): how big is the cubic field tensor side length\n",
    "            (i.e., num_bins is box side length)\n",
    "    Returns:\n",
    "        dictionary: A list of atomic density tensors (50x50x50), one for each\n",
    "            channel in channels\n",
    "    \"\"\"\n",
    "    # sets of allowed filters to build channels with\n",
    "    residue_filters = protein_dict['residue_set']\n",
    "    atom_filters = protein_dict['atom_type_set']\n",
    "    \n",
    "    general_filters = ['all_C', 'all_O', 'all_N']\n",
    "    residue_property_filters = np.array(['acidic', 'basic', 'polar', 'nonpolar',\\\n",
    "                                         'charged', 'amphipathic'])\n",
    "    smart_filters = np.array(['hydrophobic', 'aromatic', 'acceptor', 'donor',\n",
    "                             'ring'])\n",
    "    named_prop = np.array(['hyb', 'heavyvalence', 'heterovalence', 'partialcharge'])\n",
    "    other_filters = np.array(['backbone', 'sidechains'])\n",
    "\n",
    "    # consolidate into one set of filters\n",
    "    filter_set = {'atom':atom_filters, 'residue':residue_filters,\\\n",
    "                  'residue_property':residue_property_filters, \\\n",
    "                  'smarts_property':smart_filters, \\\n",
    "                  'atom_property': named_prop, 'general': general_filters,\n",
    "                  'other':other_filters}\n",
    "\n",
    "    # construct a single empty field, then initialize a dictionary with one\n",
    "    # empty field for every channel we are going to calculate the density for\n",
    "    empty_field = torch.zeros((num_bins, num_bins, num_bins))\n",
    "    fields = {channel:empty_field for channel in channels}\n",
    "\n",
    "    # create linearly spaced grid (default is -49 to 49 in steps of 2)\n",
    "    grid_1d = torch.linspace(start=-num_bins / 2 * bin_size + bin_size / 2,\n",
    "                             end=num_bins / 2 * bin_size - bin_size / 2,\n",
    "                             steps=num_bins)\n",
    "\n",
    "    # This makes three 3D meshgrids in for the x, y, and z positions\n",
    "    # These cubes will be flattened, then used as a reference coordinate system\n",
    "    # to place the actual channel densities into\n",
    "    xgrid, ygrid, zgrid = grid_positions(grid_1d)\n",
    "\n",
    "    for channel_index, channel in enumerate(channels):\n",
    "\n",
    "        # no illegal channels allowed, assume the channel sucks\n",
    "        channel_allowed = check_channel(channel, filter_set)\n",
    "\n",
    "        if channel_allowed:\n",
    "            pass\n",
    "        else:\n",
    "            #err_string = 'Allowed channels are: in a protein\\'s atom_type_set,\n",
    "                        # residue_set',or the \\'sidechains\\' and \\'backbone\\' channels.'\n",
    "            raise ValueError('The channel ', channel, ' is not allowed for this protein.')\n",
    "\n",
    "\n",
    "        # Extract positions of atoms that are part of the current channel\n",
    "\n",
    "        atom_positions = find_channel_atoms(channel, protein_dict, filter_set)\n",
    "        if channel in filter_set['atom']:\n",
    "            print('atom')\n",
    "        \n",
    "        #print('This is channel ', atom_positions)\n",
    "\n",
    "        atom_positions = torch.FloatTensor(atom_positions)\n",
    "        \n",
    "\n",
    "        # xgrid.view(-1, 1) is 125,000 long, because it's viewing a 50x50x50 cube in one column\n",
    "        # then you repeat that column horizontally for each atom\n",
    "        xx_xx = xgrid.view(-1, 1).repeat(1, len(atom_positions))\n",
    "        yy_yy = ygrid.view(-1, 1).repeat(1, len(atom_positions))\n",
    "        zz_zz = zgrid.view(-1, 1).repeat(1, len(atom_positions))\n",
    "        \n",
    "        # at this point we've created 3 arrays that are 125,000 long\n",
    "        # and as wide as the number of atoms that are the current channel type\n",
    "        # these 3 arrays just contain the flattened x,y,z positions of our 50x50x50 box\n",
    "\n",
    "\n",
    "        # now do the same thing as above, just with the ACTUAL atomic position data\n",
    "        posx_posx = atom_positions[:, 0].contiguous().view(1, -1).repeat(len(xgrid.view(-1)), 1)\n",
    "        print(xx_xx[0].shape)\n",
    "        posy_posy = atom_positions[:, 1].contiguous().view(1, -1).repeat(len(ygrid.view(-1)), 1)\n",
    "        posz_posz = atom_positions[:, 2].contiguous().view(1, -1).repeat(len(zgrid.view(-1)), 1)\n",
    "        # three tensors of the same size, with actual atomic coordinates\n",
    "\n",
    "        # normalizes the atomic positions with respect to the center of the box\n",
    "        # and calculates density of atoms in each voxel\n",
    "        sigma = 0.5*bin_size\n",
    "\n",
    "        \n",
    "        if channel in named_prop:\n",
    "            prop = []\n",
    "            for atom in protein_dict['smarts']:\n",
    "    #atom.__getattribute__(prop)\n",
    "                prop.append(atom.__getattribute__(named_prop[np.int(np.where(named_prop == channel)[0])]))\n",
    "\n",
    "            prop = np.array(prop)\n",
    "            print(max(prop))\n",
    "\n",
    "            normalized_prop =  (prop-min(prop))/(max(prop)-min(prop))\n",
    "            #print(normalized_prop)\n",
    "            \n",
    "            density = torch.exp(-(((xx_xx - posx_posx)**2) * normalized_prop\n",
    "                              + ((yy_yy - posy_posy)**2) * normalized_prop\n",
    "                              + ((zz_zz - posz_posz)**2) * normalized_prop) / (2 * (sigma)**2))\n",
    "        \n",
    "        else:\n",
    "            density = torch.exp(-((xx_xx - posx_posx)**2\n",
    "                            + (yy_yy - posy_posy)**2\n",
    "                            + (zz_zz - posz_posz)**2) / (2 * (sigma)**2))\n",
    "        print(density.shape)\n",
    "\n",
    "        # Normalize so each atom density sums to one\n",
    "        density /= torch.sum(density, dim=0)\n",
    "\n",
    "        # Sum densities and reshape to original shape\n",
    "        sum_densities = torch.sum(density, dim=1).view(xgrid.shape)\n",
    "        print(sum_densities.shape)\n",
    "\n",
    "        # set all nans to 0\n",
    "        sum_densities[sum_densities != sum_densities] = 0\n",
    "\n",
    "        # add two empty dimmensions to make it 1x1x50x50x50, needed for CNN\n",
    "        # sum_densities = sum_densities.unsqueeze(0)\n",
    "        # sum_densities = sum_densities.unsqueeze(0)\n",
    "\n",
    "        #fields[atom_type_index] = sum_densities\n",
    "        fields[channel] = sum_densities.numpy()\n",
    "\n",
    "#     if return_bins:\n",
    "#         return fields, num_bins\n",
    "#     else:\n",
    "        return fields\n",
    "\n",
    "def check_channel(channel, filter_set):\n",
    "    \"\"\"\n",
    "    This function checks to see if a channel the user is asking to make a field\n",
    "        for is an allowed channel to ask for.\n",
    "    Parameters:\n",
    "        channel (str, required): The atomic channel being requested\n",
    "        filter_set (dict, required): The set of defined atomic filters\n",
    "    Returns:\n",
    "        boolean: indicator for if the channel is allowed\n",
    "    \"\"\"\n",
    "    channel_allowed = False\n",
    "    for key in filter_set:\n",
    "        if channel in filter_set[key]:\n",
    "            channel_allowed = True\n",
    "\n",
    "    return channel_allowed\n",
    "\n",
    "def find_channel_atoms(channel, protein_dict, filter_set):\n",
    "    \"\"\"\n",
    "    This function finds the coordinates of all relevant atoms in a channel.\n",
    "    It uses the filter set to constrcut the atomic channel (i.e., a channel can\n",
    "        be composed of multiple filters).\n",
    "    Parameters:\n",
    "        channel (str, required): The atomic channel being constructed\n",
    "        protein_dict (dict, required): The dictionary of the protein, returned from\n",
    "            load_pdb()\n",
    "        filter_set (dict, required): The set of available filters to construct channels with\n",
    "    Returns:\n",
    "        numpy array:  array containing the coordinates of each atom that is relevant\n",
    "            to the channel\n",
    "    \"\"\"\n",
    "    if channel in filter_set['atom']:\n",
    "        atom_positions = protein_dict['shifted_positions'][protein_dict['atom_types'] == channel]\n",
    "    \n",
    "    elif channel in filter_set['general']:\n",
    "        atom_dict = {'all_C' :'C', 'all_O' : 'O', 'all_N' : 'N'}\n",
    "        atom_positions = protein_dict['shifted_positions']\\\n",
    "                        [[a.startswith(atom_dict[channel], 0) for a in protein_dict['atom_types']]]\n",
    "        \n",
    "\n",
    "    elif channel in filter_set['residue']:\n",
    "        atom_positions = protein_dict['shifted_positions'][protein_dict['residues'] == channel]\n",
    "        \n",
    "    elif channel in filter_set['smarts_property']:\n",
    "        smarts_list = [\n",
    "                '[#6+0!$(*~[#7,#8,F]),SH0+0v2,s+0,S^3,Cl+0,Br+0,I+0]',\n",
    "                '[a]',\n",
    "                '[!$([#1,#6,F,Cl,Br,I,o,s,nX3,#7v5,#15v5,#16v4,#16v6,*+1,*+2,*+3])]',\n",
    "                '[!$([#6,H0,-,-2,-3]),$([!H0;#7,#8,#9])]',\n",
    "                '[r]'\n",
    "            ]\n",
    "        smarts_list_entry = smarts_list[np.int(np.where(filter_set['smarts_property'] == channel)[0])]\n",
    "        pattern = pybel.Smarts(smarts_list_entry)\n",
    "        atoms_smart = np.array(list(*zip(*pattern.findall(protein_dict['smarts']))),\n",
    "                                    dtype=int) - 1\n",
    "        print(atoms_smart)\n",
    "        atom_positions = protein_dict['shifted_positions'][atoms_smart]\n",
    "    \n",
    "    elif channel in filter_set['atom_property']:\n",
    "        atom_positions = protein_dict['shifted_positions']\n",
    "\n",
    "    elif channel in filter_set['other']: # backbone or sidechain\n",
    "        if channel == 'backbone':\n",
    "            # create boolean arrays for backbone atoms\n",
    "            bool_oxygen = protein_dict['atom_types'] == 'O'\n",
    "            bool_carbon = protein_dict['atom_types'] == 'C'\n",
    "            bool_alphacarbon = protein_dict['atom_types'] == 'CA'\n",
    "            bool_nitrogen = protein_dict['atom_types'] == 'N'\n",
    "\n",
    "            # sum of all the backbone channels into one boolean array\n",
    "            bool_backbone = bool_oxygen + bool_carbon + bool_alphacarbon + bool_nitrogen\n",
    "\n",
    "            # select the backbone atoms\n",
    "            atom_positions = protein_dict['shifted_positions'][bool_backbone]\n",
    "\n",
    "        else: # it was 'sidechain' filter, so grab sidechain atoms\n",
    "            backbone_atom_set = np.array(['O', 'C', 'CA', 'N'])\n",
    "            sidechain_atom_set = np.array([atom for atom in protein_dict['atom_type_set'] \\\n",
    "                                           if atom not in backbone_atom_set])\n",
    "\n",
    "            for index, sidechain_atom in enumerate(sidechain_atom_set):\n",
    "                if index == 0:\n",
    "                    # create the first sidechains boolean array, will be edited\n",
    "                    bool_sidechains = protein_dict['atom_types'] == sidechain_atom\n",
    "                else:\n",
    "                    # single boolean array for the current sidechain atom\n",
    "                    bool_atom = protein_dict['atom_types'] == sidechain_atom\n",
    "\n",
    "                    # sum this boolean array with the master boolean array\n",
    "                    bool_sidechains += bool_atom\n",
    "\n",
    "            # grab all sidechain atom positions\n",
    "            atom_positions = protein_dict['shifted_positions'][bool_sidechains]\n",
    "\n",
    "    else: # it was a residue property channel\n",
    "        acidic_residues = np.array(['ASP', 'GLU'])\n",
    "        basic_residues = np.array(['LYS', 'ARG', 'HIS'])\n",
    "        polar_residues = np.array(['GLN', 'ASN', 'HIS', 'SER', 'THR', 'TYR', 'CYS'])\n",
    "        nonpolar_residues = np.array(['GLY', 'ALA', 'VAL', 'LEU', \\\n",
    "                                        'ILE', 'MET', 'PRO', 'PHE', 'TRP'])\n",
    "        amphipathic_residues = np.array(['TRP', 'TYR', 'MET'])\n",
    "        charged_residues = np.array(['ARG', 'LYS', 'ASP', 'GLU'])\n",
    "        # custom_residues = something\n",
    "        property_dict = {'acidic':acidic_residues, 'basic':basic_residues,\\\n",
    "                         'polar':polar_residues, 'nonpolar':nonpolar_residues,\\\n",
    "                         'amphipathic':amphipathic_residues, 'charged':charged_residues}\n",
    "\n",
    "        atom_positions = atoms_from_residues(protein_dict, property_dict[channel])\n",
    "\n",
    "    return atom_positions\n",
    "\n",
    "def atoms_from_residues(protein_dict, residue_list):\n",
    "    \"\"\"\n",
    "    This function finds all the atoms in a protein that are members of any residues\n",
    "    in a list of residues.\n",
    "    Parameters:\n",
    "        protein_dict (dict, required): The dictionary of the protein, returned from\n",
    "            load_pdb()\n",
    "        residue_list (list-like, required): The list of residues whose atoms we are\n",
    "            finding coordinates for\n",
    "    \"\"\"\n",
    "    # construct the appropriate boolean array to index the atoms in the protein_dict\n",
    "    for index, residue in enumerate(residue_list):\n",
    "        if index == 0:\n",
    "            bool_residue = protein_dict['residues'] == residue\n",
    "        else:\n",
    "            bool_residue += protein_dict['residues'] == residue\n",
    "\n",
    "    atom_positions = protein_dict['shifted_positions'][bool_residue]\n",
    "\n",
    "    return atom_positions\n",
    "\n",
    "def voxelize(path, channels=['CA'], path_type='file', bin_size=2.0, num_bins=50, save=False, save_fn='voxels.npy', save_path='./'):\n",
    "    \"\"\"\n",
    "    This function creates a dictionary of tensor fields directly from a pdb file.\n",
    "    These tensor fields can be plotted, or sent directly into the cnn for\n",
    "        plotting internals, or sent all the way through a cnn/vae to be used for\n",
    "        training.\n",
    "    Parameters:\n",
    "        path (str, required): path to a .pdb file\n",
    "        channels (list of strings, optional): The list of atomic channels to be included in\n",
    "            the output dictionary, one field for every channel.\n",
    "            Any channels from points 1-4 below may be combined in any order.\n",
    "            i.e., one could call voxelize with the channels parameter as\n",
    "            channels=['charged', 'CB', 'GLY', 'polar', ...etc]. Note that voxelization\n",
    "            for channels containing more atoms will take longer.\n",
    "            1. any of the following atom types\n",
    "                ['C' 'CA' 'CB' 'CD' 'CD1' 'CD2' 'CE' 'CE1' 'CE2' 'CE3' 'CG' 'CG1' 'CG2'\n",
    "                'CH2' 'CZ' 'CZ2' 'CZ3' 'N' 'ND1' 'ND2' 'NE' 'NE1' 'NE2' 'NH1' 'NH2' 'NZ'\n",
    "                'O' 'OD1' 'OD2' 'OE1' 'OE2' 'OG' 'OG1' 'OH' 'OXT' 'SD' 'SG']\n",
    "            2. Any canonical residue in the protein, using the three letter residue code, all caps\n",
    "               (NOTE: the residue must actually exist in the protein)\n",
    "                e.g., ['LYS', 'LEU', 'ALA']\n",
    "            3. The 'other' channel options: 'backbone', 'sidechains'\n",
    "            4. There are 6 channels corresponding to specific types of residues:\n",
    "                'charged', 'polar', 'nonpolar', 'amphipathic', 'acidic', 'basic'\n",
    "    Returns:\n",
    "        dictionary: a dictionary containing a voxelized atomic fields, one for each\n",
    "        channel requested. Each field has shape = ([1, 1, 50, 50, 50])\n",
    "    \"\"\"\n",
    "    if path_type == 'file':\n",
    "        protein_dict = load_pdb(path)\n",
    "        sys.stdout.write('done')\n",
    "        return make_fields(protein_dict, channels=channels, bin_size=bin_size, num_bins=num_bins)\n",
    "\n",
    "    # ------------FOLDER FUNCTIONALITY INCOMPLETE---------------\n",
    "    elif path_type == 'folder':\n",
    "        fields = []\n",
    "        pdb_fns = os.listdir(path)\n",
    "        for j, fn in enumerate(pdb_fns):\n",
    "            progress = '{}/{} pdbs voxelized ({}%)'.format(j, len(pdb_fns), \\\n",
    "                        round(j / len(pdb_fns) * 100, 2))\n",
    "            sys.stdout.write('\\r'+progress)\n",
    "            protein_dict = load_pdb(os.path.join(path, fn))\n",
    "            field, bins = make_fields(protein_dict, channels=channels, bin_size=bin_size, num_bins=num_bins)\n",
    "            channel_list = []\n",
    "            for channel in channels:\n",
    "                channel_list.append(field[channel].reshape(1,\n",
    "                                                           bins,\n",
    "                                                           bins,\n",
    "                                                           bins))\n",
    "            field = np.concatenate(channel_list).reshape(1,len(channels),\n",
    "                                                         bins, bins, bins)\n",
    "            fields.append(field)\n",
    "        sys.stdout.write(\"\\r\\033[K\")\n",
    "        out_statement = 'voxelization complete!\\n'\n",
    "        sys.stdout.write('\\r'+out_statement)\n",
    "        fields = np.concatenate(fields)\n",
    "\n",
    "        if save:\n",
    "            np.save(os.path.join(save_path, save_fn), fields)\n",
    "        else:\n",
    "            return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '1a1e_ligand.mol2'\n",
    "myprotein_dict = load_pdb(file_name)\n",
    "shift_coordinates = shift_coords(myprotein_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donetorch.Size([73])\n",
      "4\n",
      "torch.Size([125000, 73])\n",
      "torch.Size([50, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "voxel = voxelize(file_name, channels=['heavyvalence'], bin_size=2.0,num_bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atom\n",
      "torch.Size([2])\n",
      "torch.Size([125000, 2])\n",
      "torch.Size([50, 50, 50])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_field_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ea628a0a314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcnns4qspr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplottable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot_field_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplottable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_field_test' is not defined"
     ]
    }
   ],
   "source": [
    "field_dict = make_fields(myprotein_dict, channels = ['CA'], bin_size=2.0,num_bins=50)\n",
    "\n",
    "from cnns4qspr import visualizer\n",
    "plottable=plot_field_test(field_dict['CA'],num_bins=50, show=False)\n",
    "plottable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atom\n",
      "torch.Size([2])\n",
      "torch.Size([125000, 2])\n",
      "torch.Size([50, 50, 50])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_field_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1b48e4600ae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfield_dict_20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyprotein_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'CA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplottable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot_field_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_dict_20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplottable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_field_test' is not defined"
     ]
    }
   ],
   "source": [
    "field_dict_20 = make_fields(myprotein_dict, channels = ['CA'], bin_size=2.0,num_bins=50)\n",
    "plottable=plot_field_test(field_dict_20['CA'],num_bins=50, show=False)\n",
    "plottable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smarts_list = [\n",
    "                '[#6+0!$(*~[#7,#8,F]),SH0+0v2,s+0,S^3,Cl+0,Br+0,I+0]',\n",
    "                '[a]',\n",
    "                '[!$([#1,#6,F,Cl,Br,I,o,s,nX3,#7v5,#15v5,#16v4,#16v6,*+1,*+2,*+3])]',\n",
    "                '[!$([#6,H0,-,-2,-3]),$([!H0;#7,#8,#9])]',\n",
    "                '[r]'\n",
    "            ]\n",
    "\n",
    "smart_filters = np.array(['hydrophobic', 'aromatic', 'acceptor', 'donor',\n",
    "                             'ring'])\n",
    "\n",
    "channel = 'ring'\n",
    "# smarts_list[smart_filters==channel)]\n",
    "smarts_list_entry = smarts_list[np.int(np.where(smart_filters == channel)[0])]\n",
    "molecule = next(pybel.readfile('mol2', '1a1e_ligand.mol2'))\n",
    "pattern = pybel.Smarts(smarts_list_entry)\n",
    "atoms_with_prop = np.array(list(*zip(*pattern.findall(molecule))),\n",
    "                                       dtype=int) - 1\n",
    "atoms_with_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../PDBbind/test-set/1a1e/1a1e_ligand.mol2'\n",
    "file_type = path.split('.')[-1]\n",
    "file_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "named_prop = np.array(['hyb', 'heavyvalence', 'heterovalence', 'partialcharge'])\n",
    "\n",
    "channel = 'partialcharge'\n",
    "\n",
    "print(index)\n",
    "prop = []\n",
    "for atom in pocket:\n",
    "    #atom.__getattribute__(prop)\n",
    "    prop.append(atom.__getattribute__(named_prop[np.int(np.where(named_prop == channel)[0])]))\n",
    "\n",
    "prop = np.array(prop)\n",
    "\n",
    "normalized_prop =  (prop-min(prop))/(max(prop)-min(prop))\n",
    "norm_prop = normalized_prop.reshape(73,1)\n",
    "normalized_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This module contains functions to plot atomic density fields before\n",
    "they go into a model, as well as what the density fields have been\n",
    "transformed into at certain points within the model.\n",
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "#from cnns4qspr.featurizer import load_cnn\n",
    "\n",
    "def outer_block1_hook(module, input_, output):\n",
    "    global outer_block1_out\n",
    "    outer_block1_out = output\n",
    "\n",
    "\n",
    "def outer_block2_hook(module, input_, output):\n",
    "    global outer_block2_out\n",
    "    outer_block2_out = output\n",
    "\n",
    "\n",
    "def outer_block3_hook(module, input_, output):\n",
    "    global outer_block3_out\n",
    "    outer_block3_out = output\n",
    "\n",
    "\n",
    "def outer_block4_hook(module, input_, output):\n",
    "    global outer_block4_out\n",
    "    outer_block4_out = output\n",
    "\n",
    "\n",
    "def outer_block5_hook(module, input_, output):\n",
    "    global outer_block5_out\n",
    "    outer_block5_out = output\n",
    "\n",
    "def plot_field_test(\n",
    "        field,\n",
    "        num_bins=50,\n",
    "        color='deep',\n",
    "        threshold=0.2,\n",
    "        alpha=0.7,\n",
    "        show=True,\n",
    "        title=''):\n",
    "    \"\"\"\n",
    "    This function takes a tensorfield and plots the field density in 3D\n",
    "    space. The field describes an atomic \"density\" at each voxel.\n",
    "\n",
    "    Parameters:\n",
    "        field (pytorch tensor, required): A field from a field\n",
    "            dictionary that was output by\n",
    "            either `voxelize` or `make_fields`.\n",
    "\n",
    "        color (str, optional): The color scheme to plot the field. Any\n",
    "            of the Plotly continuous color schemes. 'deep' and 'ice_r'\n",
    "            are recommended as good baselines.\n",
    "\n",
    "        threshold (float, optional): The threshold intensity that a\n",
    "            voxel must have in order to be included in the plot.\n",
    "\n",
    "        alpha (float, optional): Amount of transparency to use in\n",
    "            plotted marks.\n",
    "\n",
    "        show (boolean, optional): Whether to show the plot. If false,\n",
    "            the plotly fig object is returned.\n",
    "\n",
    "    Returns:\n",
    "        plotly figure object: If show=False, a plotly figure object is\n",
    "        returned\n",
    "    \"\"\"\n",
    "    cube = field\n",
    "\n",
    "    cube /= cube.max()\n",
    "\n",
    "    cubelist = []\n",
    "    xval = np.linspace(-len(cube[0]) + 1, len(cube[0]) - 1, num_bins)\n",
    "    yval = np.linspace(-len(cube[0]) + 1, len(cube[0]) - 1, num_bins)\n",
    "    zval = np.linspace(-len(cube[0]) + 1, len(cube[0]) - 1, num_bins)\n",
    "\n",
    "    # make a dataframe of x,y,z,intensity for each point in the cube\n",
    "    # to do this have to loop through the cube\n",
    "    for i, xval2 in enumerate(xval):\n",
    "\n",
    "        for j, yval2 in enumerate(yval):\n",
    "\n",
    "            for k, zval2 in enumerate(zval):\n",
    "\n",
    "                cubelist.append([xval2, yval2, zval2, cube[i][j][k]])\n",
    "\n",
    "    cube_df = pd.DataFrame(cubelist, columns=['x', 'y', 'z', 'intensity'])\n",
    "\n",
    "    # only show the voxels with some intensity\n",
    "    cube_df = cube_df[cube_df['intensity'] > threshold]\n",
    "\n",
    "    fig = px.scatter_3d(cube_df, x='x', y='y', z='z',\n",
    "                        color='intensity', opacity=alpha,\n",
    "                        color_continuous_scale=color)\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(range=[-num_bins / 2.0, num_bins / 2.0]),\n",
    "            yaxis=dict(range=[-num_bins / 2.0, num_bins / 2.0]),\n",
    "            zaxis=dict(range=[-num_bins / 2.0, num_bins / 2.0])\n",
    "        ), title=title\n",
    "    )\n",
    "    if show:\n",
    "        fig.show()\n",
    "        figret = None\n",
    "    else:\n",
    "        figret = fig\n",
    "    return figret\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnns4qspr",
   "language": "python",
   "name": "cnns4qspr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
